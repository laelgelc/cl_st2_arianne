{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "810d9f10-ec19-4b09-8f90-e983e460b319",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"https://laelgelcpublic.s3.sa-east-1.amazonaws.com/lael_50_years_narrow_white.png.no_years.400px_96dpi.png\" width=\"300\" alt=\"LAEL 50 years logo\">\n",
    "<h3>APPLIED LINGUISTICS GRADUATE PROGRAMME (LAEL)</h3>\n",
    "</center>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888c2c96-2fc3-4a1a-995b-c388036a2a15",
   "metadata": {},
   "source": [
    "# Corpus Linguistics - Study 2 - Phase 1 - Arianne"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3291bbafe478f3d",
   "metadata": {},
   "source": [
    "This phase aims at extracting text from the blog posts of the following websites:\n",
    "- [Greenpeace Stories](https://www.greenpeace.org/international/story/)\n",
    "- [WWF](https://www.worldwildlife.org/stories?page=1&threat_id=effects-of-climate-change)\n",
    "- [WRI](https://www.wri.org/resources/topic/climate-53/type/insights-50?page=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a685d8b0-7715-45a6-9489-2d3db9b346c8",
   "metadata": {},
   "source": [
    "## Required Python packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e16e73-b1b9-4838-8cce-a29dc300868e",
   "metadata": {},
   "source": [
    "- beautifulsoup4\n",
    "- pandas\n",
    "- tqdm\n",
    "- selenium\n",
    "- lxml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa922755-c4d6-4008-9aad-d35e33b18ed7",
   "metadata": {},
   "source": [
    "## Import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "id": "fe5c4b76ea4f95d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T22:49:47.753128Z",
     "start_time": "2025-10-22T22:49:46.650681Z"
    }
   },
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.edge.service import Service\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.edge.options import Options"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "b1911dcf5a8425df",
   "metadata": {},
   "source": [
    "## Define input variables"
   ]
  },
  {
   "cell_type": "code",
   "id": "ffccb3260540bf52",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T22:49:50.047362Z",
     "start_time": "2025-10-22T22:49:50.044179Z"
    }
   },
   "source": [
    "input_directory = 'cl_st2_ph1_arianne'\n",
    "output_directory = 'cl_st2_ph1_arianne'"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "cb6c223aee4c74b",
   "metadata": {},
   "source": [
    "## Create output directory"
   ]
  },
  {
   "cell_type": "code",
   "id": "3cc952da8ef9ec1f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T22:49:52.277884Z",
     "start_time": "2025-10-22T22:49:52.273711Z"
    }
   },
   "source": [
    "# Check if the output directory already exists. If it does, do nothing. If it doesn't exist, create it.\n",
    "if os.path.exists(output_directory):\n",
    "    print('Output directory already exists.')\n",
    "else:\n",
    "    try:\n",
    "        os.makedirs(output_directory)\n",
    "        print('Output directory successfully created.')\n",
    "    except OSError as e:\n",
    "        print('Failed to create the directory:', e)\n",
    "        sys.exit(1)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output directory already exists.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "d70d1d62f24b7b24",
   "metadata": {},
   "source": [
    "## Set up logging"
   ]
  },
  {
   "cell_type": "code",
   "id": "b3ddac3c2e754a25",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T22:49:56.394033Z",
     "start_time": "2025-10-22T22:49:56.390811Z"
    }
   },
   "source": [
    "log_filename = f\"{output_directory}/{output_directory}.log\""
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "35dcc9ad97a25ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T22:49:58.855099Z",
     "start_time": "2025-10-22T22:49:58.852046Z"
    }
   },
   "source": [
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    filename=log_filename\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "942249a4815dda54",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f0ccb2a4a2d50c",
   "metadata": {},
   "source": [
    "### Create output subdirectories"
   ]
  },
  {
   "cell_type": "code",
   "id": "cdbf413aac1b7b7e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T22:50:01.899524Z",
     "start_time": "2025-10-22T22:50:01.896099Z"
    }
   },
   "source": [
    "def create_directory(path):\n",
    "    \"\"\"Creates a subdirectory if it doesn't exist.\"\"\"\n",
    "    if not os.path.exists(path):\n",
    "        try:\n",
    "            os.makedirs(path)\n",
    "            print(f\"Successfully created the directory: {path}\")\n",
    "        except OSError as e:\n",
    "            print(f\"Failed to create the {path} directory: {e}\")\n",
    "            sys.exit(1)\n",
    "    else:\n",
    "        print(f\"Directory already exists: {path}\")"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "bae051d781151e8e",
   "metadata": {},
   "source": [
    "### Scrape web pages"
   ]
  },
  {
   "cell_type": "code",
   "id": "5d0f699053e28d5b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T22:50:05.342392Z",
     "start_time": "2025-10-22T22:50:05.337403Z"
    }
   },
   "source": [
    "def scrape_html(url):\n",
    "    \"\"\"Loads a web page and returns its source HTML.\"\"\"\n",
    "    # Setting up the WebDriver\n",
    "    service = Service(r'C:\\Users\\eyamr\\OneDrive\\00-Technology\\msedgedriver\\edgedriver_win64\\msedgedriver.exe')\n",
    "    #service = Service('/Users/eyamrog/msedgedriver/edgedriver_mac64/msedgedriver')\n",
    "    #service = Service('/home/eyamrog/msedgedriver/edgedriver_linux64/msedgedriver')\n",
    "\n",
    "    # Configure Edge to run headless\n",
    "    options = Options()\n",
    "    # For modern Edge/Chromium; if incompatible with your version, try \"--headless\"\n",
    "    options.add_argument('--headless=new')\n",
    "    options.add_argument('--disable-gpu')\n",
    "    options.add_argument('--window-size=1920,1080')\n",
    "\n",
    "    driver = webdriver.Edge(service=service, options=options)\n",
    "    html = None\n",
    "    try:\n",
    "        driver.get(url)\n",
    "\n",
    "        # Explicit wait for stable page load\n",
    "        wait = WebDriverWait(driver, 10)\n",
    "        wait.until(EC.presence_of_element_located((By.TAG_NAME, 'body')))\n",
    "\n",
    "        # Extra reliability check: Wait until the page source stops changing\n",
    "        max_wait_time = 30\n",
    "        start_time = time.time()\n",
    "        previous_html = ''\n",
    "\n",
    "        while True:\n",
    "            current_html = driver.page_source\n",
    "            if current_html == previous_html or time.time() - start_time > max_wait_time:\n",
    "                break\n",
    "            previous_html = current_html\n",
    "            time.sleep(2)\n",
    "\n",
    "        html = driver.page_source  # Capture page source\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error scraping {url}: {e}\")\n",
    "    finally:\n",
    "        # Always close WebDriver\n",
    "        driver.quit()\n",
    "\n",
    "    return html"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T22:50:09.850143Z",
     "start_time": "2025-10-22T22:50:09.846190Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def scrape_html_2(url):\n",
    "    \"\"\"Loads a web page and returns its source HTML.\"\"\"\n",
    "    # Setting up the WebDriver\n",
    "    service = Service(r'C:\\Users\\eyamr\\OneDrive\\00-Technology\\msedgedriver\\edgedriver_win64\\msedgedriver.exe')\n",
    "    #service = Service('/Users/eyamrog/msedgedriver/edgedriver_mac64/msedgedriver')\n",
    "    #service = Service('/home/eyamrog/msedgedriver/edgedriver_linux64/msedgedriver')\n",
    "\n",
    "    # Configure Edge to run headless\n",
    "    #options = Options()\n",
    "    # For modern Edge/Chromium; if incompatible with your version, try \"--headless\"\n",
    "    #options.add_argument('--headless=new')\n",
    "    #options.add_argument('--disable-gpu')\n",
    "    #options.add_argument('--window-size=1920,1080')\n",
    "\n",
    "    #driver = webdriver.Edge(service=service, options=options)\n",
    "    driver = webdriver.Edge(service=service)\n",
    "    html = None\n",
    "    try:\n",
    "        driver.get(url)\n",
    "\n",
    "        # Explicit wait for stable page load\n",
    "        wait = WebDriverWait(driver, 10)\n",
    "        wait.until(EC.presence_of_element_located((By.TAG_NAME, 'body')))\n",
    "\n",
    "        # Extra reliability check: Wait until the page source stops changing\n",
    "        max_wait_time = 30\n",
    "        start_time = time.time()\n",
    "        previous_html = ''\n",
    "\n",
    "        while True:\n",
    "            current_html = driver.page_source\n",
    "            if current_html == previous_html or time.time() - start_time > max_wait_time:\n",
    "                break\n",
    "            previous_html = current_html\n",
    "            time.sleep(2)\n",
    "\n",
    "        html = driver.page_source  # Capture page source\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error scraping {url}: {e}\")\n",
    "    finally:\n",
    "        # Always close WebDriver\n",
    "        driver.quit()\n",
    "\n",
    "    return html"
   ],
   "id": "b08d6dbe218bc389",
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "9f931a641f74c5b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T22:50:14.135682Z",
     "start_time": "2025-10-22T22:50:14.131597Z"
    }
   },
   "source": [
    "def scrape_html_docs(df, path):\n",
    "    \"\"\"Iterates over a DataFrame and saves HTML pages within multiple WebDriver sessions.\"\"\"\n",
    "    if not os.path.exists(path):\n",
    "        try:\n",
    "            os.makedirs(path)\n",
    "        except OSError as e:\n",
    "            logging.error(f\"Failed to create the {path} directory: {e}\")\n",
    "            sys.exit(1)\n",
    "\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df), desc='Scraping HTML documents'):\n",
    "        url = row['Post URL']\n",
    "        doc_id = row['Post ID']\n",
    "        filename = os.path.join(path, f\"{doc_id}.html\")\n",
    "\n",
    "        page_source = scrape_html(url)  # Call the scrape_html function\n",
    "\n",
    "        if page_source:\n",
    "            with open(filename, 'w', encoding='utf-8') as file:\n",
    "                file.write(page_source)\n",
    "            logging.info(f\"Saved: {filename}\")"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T22:50:16.928609Z",
     "start_time": "2025-10-22T22:50:16.923598Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def scrape_html_docs_2(df, path):\n",
    "    \"\"\"Iterates over a DataFrame and saves HTML pages within multiple WebDriver sessions.\"\"\"\n",
    "    if not os.path.exists(path):\n",
    "        try:\n",
    "            os.makedirs(path)\n",
    "        except OSError as e:\n",
    "            logging.error(f\"Failed to create the {path} directory: {e}\")\n",
    "            sys.exit(1)\n",
    "\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df), desc='Scraping HTML documents'):\n",
    "        url = row['Post URL']\n",
    "        doc_id = row['Post ID']\n",
    "        filename = os.path.join(path, f\"{doc_id}.html\")\n",
    "\n",
    "        page_source = scrape_html_2(url)  # Call the scrape_html function\n",
    "\n",
    "        if page_source:\n",
    "            with open(filename, 'w', encoding='utf-8') as file:\n",
    "                file.write(page_source)\n",
    "            logging.info(f\"Saved: {filename}\")"
   ],
   "id": "a6987040498d111a",
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "id": "7ba455474af4bc4b",
   "metadata": {},
   "source": [
    "## Scraping [Greenpeace Stories](https://www.greenpeace.org/international/story/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a800858be531266",
   "metadata": {},
   "source": [
    "### Define local variables"
   ]
  },
  {
   "cell_type": "code",
   "id": "8b141ef27be1ff09",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T14:22:37.876352Z",
     "start_time": "2025-08-19T14:22:37.873484Z"
    }
   },
   "source": [
    "id = 'grp'\n",
    "path = os.path.join(output_directory, id)\n",
    "dataset_filename_1 = f\"{id}_list\"\n",
    "dataset_filename_2 = f\"{id}\""
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "b9f4345adc617bce",
   "metadata": {},
   "source": [
    "### Create output subdirectory"
   ]
  },
  {
   "cell_type": "code",
   "id": "5c77a6049e029a22",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T14:22:41.088436Z",
     "start_time": "2025-08-19T14:22:41.084667Z"
    }
   },
   "source": [
    "create_directory(path)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory already exists: cl_st2_ph1_arianne/grp\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "id": "12741feb2537795d",
   "metadata": {},
   "source": [
    "### Capture a few document pages for inspection"
   ]
  },
  {
   "cell_type": "code",
   "id": "b22eb22a0eed40cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-17T18:25:04.035742Z",
     "start_time": "2025-08-17T18:25:04.031963Z"
    }
   },
   "source": [
    "filename_sample_1 = 'greenpeace_stories_sample1.html'\n",
    "url_sample_1 = 'https://www.greenpeace.org/international/story/page/1/'\n",
    "filename_sample_11 = 'greenpeace_stories_sample11.html'\n",
    "url_sample_11 = 'https://www.greenpeace.org/international/story/77736/from-hiroshima-to-gaza-defending-peace/'\n",
    "filename_sample_2 = 'greenpeace_stories_sample2.html'\n",
    "url_sample_2 = 'https://www.greenpeace.org/international/story/page/2/'\n",
    "filename_sample_21 = 'greenpeace_stories_sample21.html'\n",
    "url_sample_21 = 'https://www.greenpeace.org/international/story/77406/boots-to-boost-justice-standing-in-solidarity-with-indonesian-migrant-fishers/'\n",
    "filename_sample_3 = 'greenpeace_stories_sample3.html'\n",
    "url_sample_3 = 'https://www.greenpeace.org/international/story/page/3/'\n",
    "filename_sample_31 = 'greenpeace_stories_sample31.html'\n",
    "url_sample_31 = 'https://www.greenpeace.org/international/story/76810/vanishing-millet-fields-endangered-sparrows-the-climate-crisis-and-taiwans-forgotten-guardians/'"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "5aa51a45833b3f03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-17T18:25:09.811132Z",
     "start_time": "2025-08-17T18:25:04.081812Z"
    }
   },
   "source": [
    "document_page_sample_1 = scrape_html(url_sample_1)\n",
    "\n",
    "with open(f'{path}/{filename_sample_1}', 'w', encoding='utf8', newline='\\n') as file:\n",
    "    file.write(document_page_sample_1)"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "7882b7a20395a30a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-17T18:25:16.873566Z",
     "start_time": "2025-08-17T18:25:09.939629Z"
    }
   },
   "source": [
    "document_page_sample_11 = scrape_html(url_sample_11)\n",
    "\n",
    "with open(f'{path}/{filename_sample_11}', 'w', encoding='utf8', newline='\\n') as file:\n",
    "    file.write(document_page_sample_11)"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "id": "31febd2f94481e3b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-17T18:25:24.777507Z",
     "start_time": "2025-08-17T18:25:16.897424Z"
    }
   },
   "source": [
    "document_page_sample_2 = scrape_html(url_sample_2)\n",
    "\n",
    "with open(f'{path}/{filename_sample_2}', 'w', encoding='utf8', newline='\\n') as file:\n",
    "    file.write(document_page_sample_2)"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "id": "1d56dd409f7a82de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-17T18:25:32.296811Z",
     "start_time": "2025-08-17T18:25:24.794426Z"
    }
   },
   "source": [
    "document_page_sample_21 = scrape_html(url_sample_21)\n",
    "\n",
    "with open(f'{path}/{filename_sample_21}', 'w', encoding='utf8', newline='\\n') as file:\n",
    "    file.write(document_page_sample_21)"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "id": "ffb47da31973ab27",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-17T18:25:40.826842Z",
     "start_time": "2025-08-17T18:25:32.315892Z"
    }
   },
   "source": [
    "document_page_sample_3 = scrape_html(url_sample_3)\n",
    "\n",
    "with open(f'{path}/{filename_sample_3}', 'w', encoding='utf8', newline='\\n') as file:\n",
    "    file.write(document_page_sample_3)"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "e4b384b766018ee9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-17T18:25:46.957816Z",
     "start_time": "2025-08-17T18:25:40.843961Z"
    }
   },
   "source": [
    "document_page_sample_31 = scrape_html(url_sample_31)\n",
    "\n",
    "with open(f'{path}/{filename_sample_31}', 'w', encoding='utf8', newline='\\n') as file:\n",
    "    file.write(document_page_sample_31)"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "id": "9cd43188047cde5e",
   "metadata": {},
   "source": [
    "### Scraping the post metadata"
   ]
  },
  {
   "cell_type": "code",
   "id": "7e4ed3a6e89f7821",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-17T18:25:46.985617Z",
     "start_time": "2025-08-17T18:25:46.976803Z"
    }
   },
   "source": [
    "def scrape_posts(source, index_page_url_1, index_page_url_2, start_page, end_page):\n",
    "    \"\"\"Iterates over a set of index pages and extracts post metadata.\"\"\"\n",
    "    data = []\n",
    "\n",
    "    for i in tqdm(range(start_page, end_page + 1)):\n",
    "        url = f\"{index_page_url_1}{i}{index_page_url_2}\"\n",
    "\n",
    "        index_page = scrape_html(url)\n",
    "\n",
    "        # Parse page source with BeautifulSoup\n",
    "        soup = BeautifulSoup(index_page, 'lxml')\n",
    "\n",
    "        # Capture the listing page content\n",
    "        listing_page_content = soup.find('div', id='listing-page-content')\n",
    "\n",
    "        # Extract the items\n",
    "        if listing_page_content:\n",
    "            list = listing_page_content.find('ul', class_='wp-block-post-template')\n",
    "            if list:\n",
    "                items = list.find_all('li')\n",
    "\n",
    "        for item in items:\n",
    "            # Extract the item body\n",
    "            body = item.find('div', class_='query-list-item-body')\n",
    "\n",
    "            # Extract the post term\n",
    "            if body:\n",
    "                post_term = body.find('div', class_='wp-block-post-terms')\n",
    "                if post_term:\n",
    "                    post_term_text = ' '.join(post_term.get_text(' ', strip=True).split()) if post_term else ''\n",
    "\n",
    "            # Extract the post tags\n",
    "            if body:\n",
    "                post_tags = body.find('div', class_='taxonomy-post_tag wp-block-post-terms')\n",
    "                if post_tags:\n",
    "                    post_tags_list = [a.get_text(strip=True) for a in post_tags.select('a[rel=\"tag\"]')]\n",
    "                    post_tags_text = \", \".join(post_tags_list) if post_tags_list else ''\n",
    "\n",
    "            # Extract the title\n",
    "            if body:\n",
    "                headline = body.find('h4', class_='query-list-item-headline wp-block-post-title')\n",
    "                title_text = ' '.join(headline.get_text(' ', strip=True).split()) if headline else ''\n",
    "\n",
    "            # Extract the post URL\n",
    "            if headline:\n",
    "                anchor_url = headline.find('a')\n",
    "                post_url = anchor_url['href'] if anchor_url else ''\n",
    "\n",
    "            ## Extract the category\n",
    "            #post_page = scrape_html(post_url)\n",
    "            #soup_article = BeautifulSoup(post_page, 'lxml')\n",
    "            #tag_wrap_issues = soup_article.find('div', class_='tag-wrap issues')\n",
    "            #if tag_wrap_issues:\n",
    "            #    anchor_category = tag_wrap_issues.find('a')\n",
    "            #    category_text = anchor_category.get_text(strip=True) if anchor_category else ''\n",
    "\n",
    "            # Extract the authors\n",
    "            if body:\n",
    "                authors = body.find('span', class_='article-list-item-author')\n",
    "                authors_text = ' '.join(authors.get_text(' ', strip=True).split()) if authors else ''\n",
    "\n",
    "            # Extract post date\n",
    "            if body:\n",
    "                post_date = body.find('div', class_='wp-block-post-date')\n",
    "                if post_date:\n",
    "                    time = post_date.find('time')\n",
    "                    post_date_time = time['datetime'] if time else ''\n",
    "\n",
    "            # Append the extracted data\n",
    "            data.append({\n",
    "                'Source': source,\n",
    "                'Post Term': post_term_text,\n",
    "                #'Category': category_text,\n",
    "                'Post Tags': post_tags_text,\n",
    "                'Title': title_text,\n",
    "                'Post URL': post_url,\n",
    "                'Authors': authors_text,\n",
    "                'Post Date': post_date_time\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(data)"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "id": "648647f99e93339a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T00:23:08.857466Z",
     "start_time": "2025-08-19T00:23:08.853858Z"
    }
   },
   "source": [
    "source = 'Greenpeace'\n",
    "index_page_url_1 = 'https://www.greenpeace.org/international/story/page/'\n",
    "index_page_url_2 = '/'\n",
    "start_page = 1\n",
    "end_page = 136"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "id": "8fb579a3ee89205a",
   "metadata": {},
   "source": "Note: On 17/08/2025, when the data was extracted, the end page was 136."
  },
  {
   "cell_type": "code",
   "id": "d093e6254ab6dbef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-17T18:25:54.291942Z",
     "start_time": "2025-08-17T18:25:47.006470Z"
    }
   },
   "source": [
    "df_grp = scrape_posts(source, index_page_url_1, index_page_url_2, start_page, end_page)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:07<00:00,  7.26s/it]\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "id": "88b4813261f7c6c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-17T18:25:54.348110Z",
     "start_time": "2025-08-17T18:25:54.331346Z"
    }
   },
   "source": [
    "df_grp['Post Date'] = pd.to_datetime(df_grp['Post Date'], errors='coerce', utc=True)"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "id": "23b6fceae805b031",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-17T18:25:54.365045Z",
     "start_time": "2025-08-17T18:25:54.358391Z"
    }
   },
   "source": [
    "df_grp['Post ID'] = id + df_grp.index.astype(str).str.zfill(6)"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "id": "8ae88142a9413b56",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T01:39:51.288327Z",
     "start_time": "2025-08-19T01:39:51.283046Z"
    }
   },
   "source": [
    "df_grp.dtypes"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Source               object\n",
       "Post Term            object\n",
       "Post Tags            object\n",
       "Title                object\n",
       "Post URL             object\n",
       "Authors              object\n",
       "Post Date    datetime64[ns]\n",
       "Post ID              object\n",
       "dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "id": "a6769754c76e665b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-17T18:25:54.522172Z",
     "start_time": "2025-08-17T18:25:54.504922Z"
    }
   },
   "source": [
    "df_grp"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       Source Post Term                          Post Tags  \\\n",
       "0  Greenpeace   Stories                        Photography   \n",
       "1  Greenpeace   Stories                            Forests   \n",
       "2  Greenpeace   Stories                 AlternativeFutures   \n",
       "3  Greenpeace   Stories                        Photography   \n",
       "4  Greenpeace   Stories                     Peace, Nuclear   \n",
       "5  Greenpeace   Stories                     Nuclear, Peace   \n",
       "6  Greenpeace   Stories                   Plastics, Oceans   \n",
       "7  Greenpeace   Stories                        Photography   \n",
       "8  Greenpeace   Stories  Climate, Health, PollutersPayPact   \n",
       "9  Greenpeace   Stories   EnergyRevolution, Peace, Nuclear   \n",
       "\n",
       "                                               Title  \\\n",
       "0                    Greenpeace Pictures of the Week   \n",
       "1  Environmental storytelling for a Chinese audie...   \n",
       "2  5 reasons Greenpeace calls for new global tax ...   \n",
       "3                    Greenpeace Pictures of the Week   \n",
       "4            From Hiroshima to Gaza: defending peace   \n",
       "5  80 years since Hiroshima and Nagasaki — time f...   \n",
       "6  More businesses join the call for a strong UN ...   \n",
       "7                    Greenpeace Pictures of the Week   \n",
       "8  The climate crisis hits health care in South A...   \n",
       "9  How can we protect peace and democracy? Greenp...   \n",
       "\n",
       "                                            Post URL  \\\n",
       "0  https://www.greenpeace.org/international/story...   \n",
       "1  https://www.greenpeace.org/international/story...   \n",
       "2  https://www.greenpeace.org/international/story...   \n",
       "3  https://www.greenpeace.org/international/story...   \n",
       "4  https://www.greenpeace.org/international/story...   \n",
       "5  https://www.greenpeace.org/international/story...   \n",
       "6  https://www.greenpeace.org/international/story...   \n",
       "7  https://www.greenpeace.org/international/story...   \n",
       "8  https://www.greenpeace.org/international/story...   \n",
       "9  https://www.greenpeace.org/international/story...   \n",
       "\n",
       "                    Authors                 Post Date    Post ID  \n",
       "0  Greenpeace International 2025-08-15 01:45:33+00:00  grp000000  \n",
       "1               August Rick 2025-08-14 01:40:25+00:00  grp000001  \n",
       "2                Nina Stros 2025-08-13 13:47:04+00:00  grp000002  \n",
       "3  Greenpeace International 2025-08-08 05:09:19+00:00  grp000003  \n",
       "4         Greenpeace France 2025-08-07 15:22:58+00:00  grp000004  \n",
       "5              Sam Annesley 2025-08-06 00:15:55+00:00  grp000005  \n",
       "6                Sarah King 2025-08-01 06:00:00+00:00  grp000006  \n",
       "7  Greenpeace International 2025-08-01 04:08:33+00:00  grp000007  \n",
       "8            Yoliswa Sobuwa 2025-07-31 09:05:58+00:00  grp000008  \n",
       "9            Camilo Sanchez 2025-07-30 11:58:55+00:00  grp000009  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Post Term</th>\n",
       "      <th>Post Tags</th>\n",
       "      <th>Title</th>\n",
       "      <th>Post URL</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Post Date</th>\n",
       "      <th>Post ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Stories</td>\n",
       "      <td>Photography</td>\n",
       "      <td>Greenpeace Pictures of the Week</td>\n",
       "      <td>https://www.greenpeace.org/international/story...</td>\n",
       "      <td>Greenpeace International</td>\n",
       "      <td>2025-08-15 01:45:33+00:00</td>\n",
       "      <td>grp000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Stories</td>\n",
       "      <td>Forests</td>\n",
       "      <td>Environmental storytelling for a Chinese audie...</td>\n",
       "      <td>https://www.greenpeace.org/international/story...</td>\n",
       "      <td>August Rick</td>\n",
       "      <td>2025-08-14 01:40:25+00:00</td>\n",
       "      <td>grp000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Stories</td>\n",
       "      <td>AlternativeFutures</td>\n",
       "      <td>5 reasons Greenpeace calls for new global tax ...</td>\n",
       "      <td>https://www.greenpeace.org/international/story...</td>\n",
       "      <td>Nina Stros</td>\n",
       "      <td>2025-08-13 13:47:04+00:00</td>\n",
       "      <td>grp000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Stories</td>\n",
       "      <td>Photography</td>\n",
       "      <td>Greenpeace Pictures of the Week</td>\n",
       "      <td>https://www.greenpeace.org/international/story...</td>\n",
       "      <td>Greenpeace International</td>\n",
       "      <td>2025-08-08 05:09:19+00:00</td>\n",
       "      <td>grp000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Stories</td>\n",
       "      <td>Peace, Nuclear</td>\n",
       "      <td>From Hiroshima to Gaza: defending peace</td>\n",
       "      <td>https://www.greenpeace.org/international/story...</td>\n",
       "      <td>Greenpeace France</td>\n",
       "      <td>2025-08-07 15:22:58+00:00</td>\n",
       "      <td>grp000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Stories</td>\n",
       "      <td>Nuclear, Peace</td>\n",
       "      <td>80 years since Hiroshima and Nagasaki — time f...</td>\n",
       "      <td>https://www.greenpeace.org/international/story...</td>\n",
       "      <td>Sam Annesley</td>\n",
       "      <td>2025-08-06 00:15:55+00:00</td>\n",
       "      <td>grp000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Stories</td>\n",
       "      <td>Plastics, Oceans</td>\n",
       "      <td>More businesses join the call for a strong UN ...</td>\n",
       "      <td>https://www.greenpeace.org/international/story...</td>\n",
       "      <td>Sarah King</td>\n",
       "      <td>2025-08-01 06:00:00+00:00</td>\n",
       "      <td>grp000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Stories</td>\n",
       "      <td>Photography</td>\n",
       "      <td>Greenpeace Pictures of the Week</td>\n",
       "      <td>https://www.greenpeace.org/international/story...</td>\n",
       "      <td>Greenpeace International</td>\n",
       "      <td>2025-08-01 04:08:33+00:00</td>\n",
       "      <td>grp000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Stories</td>\n",
       "      <td>Climate, Health, PollutersPayPact</td>\n",
       "      <td>The climate crisis hits health care in South A...</td>\n",
       "      <td>https://www.greenpeace.org/international/story...</td>\n",
       "      <td>Yoliswa Sobuwa</td>\n",
       "      <td>2025-07-31 09:05:58+00:00</td>\n",
       "      <td>grp000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Stories</td>\n",
       "      <td>EnergyRevolution, Peace, Nuclear</td>\n",
       "      <td>How can we protect peace and democracy? Greenp...</td>\n",
       "      <td>https://www.greenpeace.org/international/story...</td>\n",
       "      <td>Camilo Sanchez</td>\n",
       "      <td>2025-07-30 11:58:55+00:00</td>\n",
       "      <td>grp000009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "id": "a92fe2e83c49a37e",
   "metadata": {},
   "source": [
    "#### Export to a file"
   ]
  },
  {
   "cell_type": "code",
   "id": "5b313a713db23d83",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-17T18:25:54.888211Z",
     "start_time": "2025-08-17T18:25:54.858579Z"
    }
   },
   "source": [
    "df_grp.to_json(f\"{output_directory}/{dataset_filename_1}.jsonl\", orient='records', lines=True)"
   ],
   "outputs": [],
   "execution_count": 25
  },
  {
   "cell_type": "markdown",
   "id": "2d296641cca1b3e9",
   "metadata": {},
   "source": [
    "### Scrape the posts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472cfcf099f77932",
   "metadata": {},
   "source": [
    "#### Import the data into a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "id": "6f4a8a03e79cbd41",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T14:28:35.407650Z",
     "start_time": "2025-08-19T14:28:35.383371Z"
    }
   },
   "source": [
    "df_grp = pd.read_json(f\"{input_directory}/{dataset_filename_1}.jsonl\", lines=True)"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "id": "5a9d2a7880cc6530",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T14:28:39.472175Z",
     "start_time": "2025-08-19T14:28:39.467354Z"
    }
   },
   "source": [
    "df_grp['Post Date'] = pd.to_datetime(df_grp['Post Date'], unit='ms')"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "id": "aa8e70c3af2b2549",
   "metadata": {},
   "source": [
    "#### Scrape the posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b82ad4481a82c218",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-15T22:10:17.794922Z",
     "start_time": "2025-08-15T22:09:06.470012Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping HTML documents: 100%|██████████| 10/10 [00:56<00:00,  5.66s/it]\n"
     ]
    }
   ],
   "source": [
    "scrape_html_docs(df_grp, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4eafbd66410fc22",
   "metadata": {},
   "source": [
    "### Extract the text from the posts"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T00:25:26.473115Z",
     "start_time": "2025-08-19T00:25:26.466127Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_text(df, path):\n",
    "    \"\"\"Extracts text from HTML files and saves as text files.\"\"\"\n",
    "\n",
    "    for post_id in df['Post ID']:\n",
    "        html_file = os.path.join(path, f\"{post_id}.html\")\n",
    "        txt_file = os.path.join(path, f\"{post_id}.txt\")\n",
    "\n",
    "        # Check if the HTML file exists\n",
    "        if not os.path.exists(html_file):\n",
    "            logging.error(f\"Skipping {html_file}: File not found\")\n",
    "            continue\n",
    "\n",
    "        # Read HTML content\n",
    "        with open(html_file, 'r', encoding='utf-8') as file:\n",
    "            soup = BeautifulSoup(file, 'lxml')\n",
    "\n",
    "        # Initialise text variable\n",
    "        text = ''\n",
    "\n",
    "        # Web Scraping - Begin\n",
    "\n",
    "        # Capture the 'article body'\n",
    "        post_body = soup.find('article')\n",
    "\n",
    "        # Extract the category\n",
    "        if post_body:\n",
    "            tag_wrap_issues = post_body.find('div', class_='tag-wrap issues')\n",
    "            if tag_wrap_issues:\n",
    "                anchor_category = tag_wrap_issues.find('a')\n",
    "                if anchor_category:\n",
    "                    category_text = ' '.join(anchor_category.get_text(' ', strip=True).split())\n",
    "                    text += f\"Category: {category_text}\\n\"\n",
    "\n",
    "        # Extract the paragraphs\n",
    "        if post_body:\n",
    "            post_content = post_body.find('div', class_='post-content')\n",
    "            if post_content:\n",
    "                post_details = post_content.find('div', class_='post-details clearfix')\n",
    "                if post_details:\n",
    "                    # Iterate top-level content blocks in order: paragraphs and lists\n",
    "                    for block in post_details.find_all(['p', 'ul', 'ol'], recursive=False):\n",
    "                        if block.name == 'p':\n",
    "                            paragraph_text = ' '.join(block.get_text(' ', strip=True).split())\n",
    "                            text += f\"{paragraph_text}\\n\"\n",
    "                        elif block.name in ('ul', 'ol'):\n",
    "                            # Capture top-level list items in order\n",
    "                            for li in block.find_all('li', recursive=False):\n",
    "                                li_text = ' '.join(li.get_text(' ', strip=True).split())\n",
    "                                text += f\"{li_text}\\n\"\n",
    "\n",
    "        # Web Scraping - End\n",
    "\n",
    "        # Save text to a text file\n",
    "        with open(txt_file, 'w', encoding='utf-8', newline='\\n') as file:\n",
    "            file.write(text)\n",
    "\n",
    "        logging.info(f\"Saved text for {post_id} to {txt_file}\")"
   ],
   "id": "8ec608d506db368b",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T01:38:00.629884Z",
     "start_time": "2025-08-19T01:37:05.750706Z"
    }
   },
   "cell_type": "code",
   "source": "extract_text(df_grp, path)",
   "id": "51525f10063d5779",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T14:24:43.362200Z",
     "start_time": "2025-08-19T14:24:43.354569Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_text_gp000071_gp001092(df, path):\n",
    "    \"\"\"Extracts text from HTML files and saves as text files.\"\"\"\n",
    "\n",
    "    for post_id in df['Post ID']:\n",
    "        html_file = os.path.join(path, f\"{post_id}.html\")\n",
    "        txt_file = os.path.join(path, f\"{post_id}.txt\")\n",
    "\n",
    "        # Check if the HTML file exists\n",
    "        if not os.path.exists(html_file):\n",
    "            logging.error(f\"Skipping {html_file}: File not found\")\n",
    "            continue\n",
    "\n",
    "        # Read HTML content\n",
    "        with open(html_file, 'r', encoding='utf-8') as file:\n",
    "            soup = BeautifulSoup(file, 'lxml')\n",
    "\n",
    "        # Initialise text variable\n",
    "        text = ''\n",
    "\n",
    "        # Web Scraping - Begin\n",
    "\n",
    "        # Capture the 'article body'\n",
    "        post_body = soup.find('article')\n",
    "\n",
    "        # Extract the category\n",
    "        if post_body:\n",
    "            tag_wrap_issues = post_body.find('div', class_='tag-wrap issues')\n",
    "            if tag_wrap_issues:\n",
    "                anchor_category = tag_wrap_issues.find('a')\n",
    "                if anchor_category:\n",
    "                    category_text = ' '.join(anchor_category.get_text(' ', strip=True).split())\n",
    "                    text += f\"Category: {category_text}\\n\"\n",
    "\n",
    "        # Extract the paragraphs\n",
    "        if post_body:\n",
    "            post_content = post_body.find('div', class_='post-content')\n",
    "            if post_content:\n",
    "                post_details = post_content.find('div', class_='post-details clearfix')\n",
    "                if post_details:\n",
    "                    # Iterate top-level content blocks in order: paragraphs and lists\n",
    "                    for block in post_details.find_all(['p', 'ul', 'ol'], recursive=True):\n",
    "                        if block.name == 'p':\n",
    "                            paragraph_text = ' '.join(block.get_text(' ', strip=True).split())\n",
    "                            text += f\"{paragraph_text}\\n\"\n",
    "                        elif block.name in ('ul', 'ol'):\n",
    "                            # Capture top-level list items in order\n",
    "                            for li in block.find_all('li', recursive=False):\n",
    "                                li_text = ' '.join(li.get_text(' ', strip=True).split())\n",
    "                                text += f\"{li_text}\\n\"\n",
    "\n",
    "        # Web Scraping - End\n",
    "\n",
    "        # Save text to a text file\n",
    "        with open(txt_file, 'w', encoding='utf-8', newline='\\n') as file:\n",
    "            file.write(text)\n",
    "\n",
    "        logging.info(f\"Saved text for {post_id} to {txt_file}\")"
   ],
   "id": "b90b6fd6938af534",
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "id": "1802069d1b6d7c3f",
   "metadata": {},
   "source": [
    "### Break down the texts into paragraphs"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T14:28:59.038323Z",
     "start_time": "2025-08-19T14:28:57.783687Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Prepare to collect rows\n",
    "data = []\n",
    "\n",
    "# Loop through each 'Post ID' in the DataFrame\n",
    "for _, row in df_grp.iterrows():\n",
    "    post_id = row['Post ID']\n",
    "\n",
    "    paragraph_count = 0\n",
    "    file_path = os.path.join(path, f\"{post_id}.txt\")\n",
    "\n",
    "    if not os.path.isfile(file_path):\n",
    "        print(f\"Missing file: {file_path}\")\n",
    "        continue\n",
    "\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            line = ' '.join(line.split()).strip()\n",
    "            if not line:\n",
    "                continue\n",
    "\n",
    "            if line.startswith('Category:'):\n",
    "                category_name = line.partition(':')[2].strip()\n",
    "                # If a category line is blank or only has the colon, we gracefully assign the fallback name 'Undefined Category'\n",
    "                category = category_name if category_name else 'Undefined Category'\n",
    "                paragraph_count = 0 # Resetting paragraph count for new category\n",
    "\n",
    "            elif line:\n",
    "                paragraph_count += 1\n",
    "                data.append({\n",
    "                    'Post ID': post_id,\n",
    "                    'Category': category,\n",
    "                    'Paragraph': f\"Paragraph {paragraph_count}\",\n",
    "                    'Text Paragraph': line\n",
    "                    })\n",
    "\n",
    "# Create final DataFrame\n",
    "df_paragraph = pd.DataFrame(data)"
   ],
   "id": "e8ce57fc839c0de2",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T14:29:02.524843Z",
     "start_time": "2025-08-19T14:29:02.514275Z"
    }
   },
   "cell_type": "code",
   "source": "df_paragraph",
   "id": "5e138d14129fb9d4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         Post ID    Category     Paragraph  \\\n",
       "0      grp000000  Greenpeace   Paragraph 1   \n",
       "1      grp000000  Greenpeace   Paragraph 2   \n",
       "2      grp000000  Greenpeace   Paragraph 3   \n",
       "3      grp000000  Greenpeace   Paragraph 4   \n",
       "4      grp000000  Greenpeace   Paragraph 5   \n",
       "...          ...         ...           ...   \n",
       "23415  grp001356  Greenpeace  Paragraph 13   \n",
       "23416  grp001356  Greenpeace  Paragraph 14   \n",
       "23417  grp001356  Greenpeace  Paragraph 15   \n",
       "23418  grp001356  Greenpeace  Paragraph 16   \n",
       "23419  grp001356  Greenpeace  Paragraph 17   \n",
       "\n",
       "                                          Text Paragraph  \n",
       "0      From a banner protest at the plastic treaty in...  \n",
       "1      🇬🇧 England – Greenpeace UK’s climbers install ...  \n",
       "2      After securing a giant 12m x 8m canvas to one ...  \n",
       "3      The work starkly visualises the wound inflicte...  \n",
       "4      🇨🇭 Switzerland – Juan Carlos Monterrey Gómez, ...  \n",
       "...                                                  ...  \n",
       "23415  He joined Toronto’s City TV as an ecology spec...  \n",
       "23416  Over the years he continued to contribute to G...  \n",
       "23417  In a recent book, Rex Weyler writes about refl...  \n",
       "23418  “The ironies and tension of history simultaneo...  \n",
       "23419  Bob Hunter made much of his opportunity to ser...  \n",
       "\n",
       "[23420 rows x 4 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Post ID</th>\n",
       "      <th>Category</th>\n",
       "      <th>Paragraph</th>\n",
       "      <th>Text Paragraph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>grp000000</td>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Paragraph 1</td>\n",
       "      <td>From a banner protest at the plastic treaty in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>grp000000</td>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Paragraph 2</td>\n",
       "      <td>🇬🇧 England – Greenpeace UK’s climbers install ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>grp000000</td>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Paragraph 3</td>\n",
       "      <td>After securing a giant 12m x 8m canvas to one ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>grp000000</td>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Paragraph 4</td>\n",
       "      <td>The work starkly visualises the wound inflicte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>grp000000</td>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Paragraph 5</td>\n",
       "      <td>🇨🇭 Switzerland – Juan Carlos Monterrey Gómez, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23415</th>\n",
       "      <td>grp001356</td>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Paragraph 13</td>\n",
       "      <td>He joined Toronto’s City TV as an ecology spec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23416</th>\n",
       "      <td>grp001356</td>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Paragraph 14</td>\n",
       "      <td>Over the years he continued to contribute to G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23417</th>\n",
       "      <td>grp001356</td>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Paragraph 15</td>\n",
       "      <td>In a recent book, Rex Weyler writes about refl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23418</th>\n",
       "      <td>grp001356</td>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Paragraph 16</td>\n",
       "      <td>“The ironies and tension of history simultaneo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23419</th>\n",
       "      <td>grp001356</td>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Paragraph 17</td>\n",
       "      <td>Bob Hunter made much of his opportunity to ser...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23420 rows × 4 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Merge `df_grp` into `df_paragraph` to obtain `df_grp_paragraph`",
   "id": "973d5fe7f6d6eabb"
  },
  {
   "cell_type": "code",
   "id": "e2e1d9af365ed797",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T14:29:06.346979Z",
     "start_time": "2025-08-19T14:29:06.326312Z"
    }
   },
   "source": [
    "df_grp_paragraph = df_grp.merge(df_paragraph, on='Post ID', how='left')"
   ],
   "outputs": [],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "id": "638f21b10c8540cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T14:29:10.735175Z",
     "start_time": "2025-08-19T14:29:10.720509Z"
    }
   },
   "source": [
    "df_grp_paragraph"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "           Source Post Term         Post Tags  \\\n",
       "0      Greenpeace   Stories       Photography   \n",
       "1      Greenpeace   Stories       Photography   \n",
       "2      Greenpeace   Stories       Photography   \n",
       "3      Greenpeace   Stories       Photography   \n",
       "4      Greenpeace   Stories       Photography   \n",
       "...           ...       ...               ...   \n",
       "23415  Greenpeace   Stories  AboutUs, 50Years   \n",
       "23416  Greenpeace   Stories  AboutUs, 50Years   \n",
       "23417  Greenpeace   Stories  AboutUs, 50Years   \n",
       "23418  Greenpeace   Stories  AboutUs, 50Years   \n",
       "23419  Greenpeace   Stories  AboutUs, 50Years   \n",
       "\n",
       "                                 Title  \\\n",
       "0      Greenpeace Pictures of the Week   \n",
       "1      Greenpeace Pictures of the Week   \n",
       "2      Greenpeace Pictures of the Week   \n",
       "3      Greenpeace Pictures of the Week   \n",
       "4      Greenpeace Pictures of the Week   \n",
       "...                                ...   \n",
       "23415           Bob Hunter 1941 – 2005   \n",
       "23416           Bob Hunter 1941 – 2005   \n",
       "23417           Bob Hunter 1941 – 2005   \n",
       "23418           Bob Hunter 1941 – 2005   \n",
       "23419           Bob Hunter 1941 – 2005   \n",
       "\n",
       "                                                Post URL  \\\n",
       "0      https://www.greenpeace.org/international/story...   \n",
       "1      https://www.greenpeace.org/international/story...   \n",
       "2      https://www.greenpeace.org/international/story...   \n",
       "3      https://www.greenpeace.org/international/story...   \n",
       "4      https://www.greenpeace.org/international/story...   \n",
       "...                                                  ...   \n",
       "23415  https://www.greenpeace.org/international/story...   \n",
       "23416  https://www.greenpeace.org/international/story...   \n",
       "23417  https://www.greenpeace.org/international/story...   \n",
       "23418  https://www.greenpeace.org/international/story...   \n",
       "23419  https://www.greenpeace.org/international/story...   \n",
       "\n",
       "                        Authors           Post Date    Post ID    Category  \\\n",
       "0      Greenpeace International 2025-08-15 01:45:33  grp000000  Greenpeace   \n",
       "1      Greenpeace International 2025-08-15 01:45:33  grp000000  Greenpeace   \n",
       "2      Greenpeace International 2025-08-15 01:45:33  grp000000  Greenpeace   \n",
       "3      Greenpeace International 2025-08-15 01:45:33  grp000000  Greenpeace   \n",
       "4      Greenpeace International 2025-08-15 01:45:33  grp000000  Greenpeace   \n",
       "...                         ...                 ...        ...         ...   \n",
       "23415  Greenpeace International 2005-05-02 15:15:00  grp001356  Greenpeace   \n",
       "23416  Greenpeace International 2005-05-02 15:15:00  grp001356  Greenpeace   \n",
       "23417  Greenpeace International 2005-05-02 15:15:00  grp001356  Greenpeace   \n",
       "23418  Greenpeace International 2005-05-02 15:15:00  grp001356  Greenpeace   \n",
       "23419  Greenpeace International 2005-05-02 15:15:00  grp001356  Greenpeace   \n",
       "\n",
       "          Paragraph                                     Text Paragraph  \n",
       "0       Paragraph 1  From a banner protest at the plastic treaty in...  \n",
       "1       Paragraph 2  🇬🇧 England – Greenpeace UK’s climbers install ...  \n",
       "2       Paragraph 3  After securing a giant 12m x 8m canvas to one ...  \n",
       "3       Paragraph 4  The work starkly visualises the wound inflicte...  \n",
       "4       Paragraph 5  🇨🇭 Switzerland – Juan Carlos Monterrey Gómez, ...  \n",
       "...             ...                                                ...  \n",
       "23415  Paragraph 13  He joined Toronto’s City TV as an ecology spec...  \n",
       "23416  Paragraph 14  Over the years he continued to contribute to G...  \n",
       "23417  Paragraph 15  In a recent book, Rex Weyler writes about refl...  \n",
       "23418  Paragraph 16  “The ironies and tension of history simultaneo...  \n",
       "23419  Paragraph 17  Bob Hunter made much of his opportunity to ser...  \n",
       "\n",
       "[23420 rows x 11 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Post Term</th>\n",
       "      <th>Post Tags</th>\n",
       "      <th>Title</th>\n",
       "      <th>Post URL</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Post Date</th>\n",
       "      <th>Post ID</th>\n",
       "      <th>Category</th>\n",
       "      <th>Paragraph</th>\n",
       "      <th>Text Paragraph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Stories</td>\n",
       "      <td>Photography</td>\n",
       "      <td>Greenpeace Pictures of the Week</td>\n",
       "      <td>https://www.greenpeace.org/international/story...</td>\n",
       "      <td>Greenpeace International</td>\n",
       "      <td>2025-08-15 01:45:33</td>\n",
       "      <td>grp000000</td>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Paragraph 1</td>\n",
       "      <td>From a banner protest at the plastic treaty in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Stories</td>\n",
       "      <td>Photography</td>\n",
       "      <td>Greenpeace Pictures of the Week</td>\n",
       "      <td>https://www.greenpeace.org/international/story...</td>\n",
       "      <td>Greenpeace International</td>\n",
       "      <td>2025-08-15 01:45:33</td>\n",
       "      <td>grp000000</td>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Paragraph 2</td>\n",
       "      <td>🇬🇧 England – Greenpeace UK’s climbers install ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Stories</td>\n",
       "      <td>Photography</td>\n",
       "      <td>Greenpeace Pictures of the Week</td>\n",
       "      <td>https://www.greenpeace.org/international/story...</td>\n",
       "      <td>Greenpeace International</td>\n",
       "      <td>2025-08-15 01:45:33</td>\n",
       "      <td>grp000000</td>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Paragraph 3</td>\n",
       "      <td>After securing a giant 12m x 8m canvas to one ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Stories</td>\n",
       "      <td>Photography</td>\n",
       "      <td>Greenpeace Pictures of the Week</td>\n",
       "      <td>https://www.greenpeace.org/international/story...</td>\n",
       "      <td>Greenpeace International</td>\n",
       "      <td>2025-08-15 01:45:33</td>\n",
       "      <td>grp000000</td>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Paragraph 4</td>\n",
       "      <td>The work starkly visualises the wound inflicte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Stories</td>\n",
       "      <td>Photography</td>\n",
       "      <td>Greenpeace Pictures of the Week</td>\n",
       "      <td>https://www.greenpeace.org/international/story...</td>\n",
       "      <td>Greenpeace International</td>\n",
       "      <td>2025-08-15 01:45:33</td>\n",
       "      <td>grp000000</td>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Paragraph 5</td>\n",
       "      <td>🇨🇭 Switzerland – Juan Carlos Monterrey Gómez, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23415</th>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Stories</td>\n",
       "      <td>AboutUs, 50Years</td>\n",
       "      <td>Bob Hunter 1941 – 2005</td>\n",
       "      <td>https://www.greenpeace.org/international/story...</td>\n",
       "      <td>Greenpeace International</td>\n",
       "      <td>2005-05-02 15:15:00</td>\n",
       "      <td>grp001356</td>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Paragraph 13</td>\n",
       "      <td>He joined Toronto’s City TV as an ecology spec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23416</th>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Stories</td>\n",
       "      <td>AboutUs, 50Years</td>\n",
       "      <td>Bob Hunter 1941 – 2005</td>\n",
       "      <td>https://www.greenpeace.org/international/story...</td>\n",
       "      <td>Greenpeace International</td>\n",
       "      <td>2005-05-02 15:15:00</td>\n",
       "      <td>grp001356</td>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Paragraph 14</td>\n",
       "      <td>Over the years he continued to contribute to G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23417</th>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Stories</td>\n",
       "      <td>AboutUs, 50Years</td>\n",
       "      <td>Bob Hunter 1941 – 2005</td>\n",
       "      <td>https://www.greenpeace.org/international/story...</td>\n",
       "      <td>Greenpeace International</td>\n",
       "      <td>2005-05-02 15:15:00</td>\n",
       "      <td>grp001356</td>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Paragraph 15</td>\n",
       "      <td>In a recent book, Rex Weyler writes about refl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23418</th>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Stories</td>\n",
       "      <td>AboutUs, 50Years</td>\n",
       "      <td>Bob Hunter 1941 – 2005</td>\n",
       "      <td>https://www.greenpeace.org/international/story...</td>\n",
       "      <td>Greenpeace International</td>\n",
       "      <td>2005-05-02 15:15:00</td>\n",
       "      <td>grp001356</td>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Paragraph 16</td>\n",
       "      <td>“The ironies and tension of history simultaneo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23419</th>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Stories</td>\n",
       "      <td>AboutUs, 50Years</td>\n",
       "      <td>Bob Hunter 1941 – 2005</td>\n",
       "      <td>https://www.greenpeace.org/international/story...</td>\n",
       "      <td>Greenpeace International</td>\n",
       "      <td>2005-05-02 15:15:00</td>\n",
       "      <td>grp001356</td>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Paragraph 17</td>\n",
       "      <td>Bob Hunter made much of his opportunity to ser...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23420 rows × 11 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Find texts that are empty",
   "id": "868c915ab24f962e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T14:29:19.348541Z",
     "start_time": "2025-08-19T14:29:19.335147Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Find rows where the specified column has empty strings\n",
    "mask = df_grp_paragraph['Category'].isnull()\n",
    "\n",
    "# Get the corresponding 'Post ID' values\n",
    "post_ids_with_missing_text = df_grp_paragraph[mask]['Post ID'].tolist()\n",
    "\n",
    "post_ids_with_missing_text"
   ],
   "id": "bcd6d57fb89be712",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T14:29:28.930674Z",
     "start_time": "2025-08-19T14:29:28.921520Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_grp_empty = df_grp_paragraph[df_grp_paragraph['Category'].isnull()]\n",
    "df_grp_empty"
   ],
   "id": "c9d757f2e97f4610",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Source, Post Term, Post Tags, Title, Post URL, Authors, Post Date, Post ID, Category, Paragraph, Text Paragraph]\n",
       "Index: []"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Post Term</th>\n",
       "      <th>Post Tags</th>\n",
       "      <th>Title</th>\n",
       "      <th>Post URL</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Post Date</th>\n",
       "      <th>Post ID</th>\n",
       "      <th>Category</th>\n",
       "      <th>Paragraph</th>\n",
       "      <th>Text Paragraph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Rescrape",
   "id": "916887215abfec20"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T01:35:38.108711Z",
     "start_time": "2025-08-19T01:35:24.630809Z"
    }
   },
   "cell_type": "code",
   "source": "scrape_html_docs(df_grp_empty, path)",
   "id": "f6833d2f23c54286",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping HTML documents: 100%|██████████| 2/2 [00:13<00:00,  6.73s/it]\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T14:25:44.620295Z",
     "start_time": "2025-08-19T14:25:44.402131Z"
    }
   },
   "cell_type": "code",
   "source": "extract_text_gp000071_gp001092(df_grp_empty, path)",
   "id": "bb90581bfd943d0f",
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "id": "96e31052da81b7a5",
   "metadata": {},
   "source": [
    "#### Export to a file"
   ]
  },
  {
   "cell_type": "code",
   "id": "78f33d144be98470",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T14:29:38.185543Z",
     "start_time": "2025-08-19T14:29:37.920071Z"
    }
   },
   "source": [
    "df_grp_paragraph.to_json(f\"{output_directory}/{dataset_filename_2}.jsonl\", orient='records', lines=True)"
   ],
   "outputs": [],
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "id": "ef3e74f35933826d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T14:29:46.595231Z",
     "start_time": "2025-08-19T14:29:40.314615Z"
    }
   },
   "source": [
    "df_grp_paragraph.to_excel(f\"{output_directory}/{dataset_filename_2}.xlsx\", index=False)"
   ],
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Scraping [WWF Conservation Stories](https://www.worldwildlife.org/news/stories/)",
   "id": "a65c9e1dfb8c2f42"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Define local variables",
   "id": "81eaecde91f78206"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T22:50:37.637695Z",
     "start_time": "2025-10-22T22:50:37.634996Z"
    }
   },
   "cell_type": "code",
   "source": [
    "id = 'wwf'\n",
    "path = os.path.join(output_directory, id)\n",
    "dataset_filename_1 = f\"{id}_list\"\n",
    "dataset_filename_2 = f\"{id}\""
   ],
   "id": "ccc3a0ce09b18996",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Create output subdirectory",
   "id": "fb0459ec8b1907aa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T22:50:40.861074Z",
     "start_time": "2025-10-22T22:50:40.857930Z"
    }
   },
   "cell_type": "code",
   "source": "create_directory(path)",
   "id": "8bc06c75270325cf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory already exists: cl_st2_ph1_arianne\\wwf\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Capture a few document pages for inspection",
   "id": "d2fe1f1441c4f312"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T19:52:56.117981Z",
     "start_time": "2025-10-22T19:52:56.111111Z"
    }
   },
   "cell_type": "code",
   "source": [
    "filename_sample_1 = 'wwf_stories_sample1.html'\n",
    "url_sample_1 = 'https://www.worldwildlife.org/news/stories/?page=1'\n",
    "filename_sample_11 = 'wwf_stories_sample11.html'\n",
    "url_sample_11 = 'https://www.worldwildlife.org/news/stories/small-steps-to-reduce-food-waste/'\n",
    "filename_sample_12 = 'wwf_stories_sample12.html'\n",
    "url_sample_12 = 'https://www.worldwildlife.org/news/stories/97-of-migratory-fish-are-going-extinct-swimways-are-a-critical-solution/'\n",
    "filename_sample_2 = 'wwf_stories_sample2.html'\n",
    "url_sample_2 = 'https://www.worldwildlife.org/news/stories/?page=3'\n",
    "filename_sample_21 = 'wwf_stories_sample21.html'\n",
    "url_sample_21 = 'https://www.worldwildlife.org/news/stories/meet-the-biggest-animal-in-the-world/'\n",
    "filename_sample_22 = 'wwf_stories_sample22.html'\n",
    "url_sample_22 = 'https://www.worldwildlife.org/news/stories/a-silver-lining-reframing-climate-through-nature/'"
   ],
   "id": "f22ad9b00ce1d89",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T19:53:18.852894Z",
     "start_time": "2025-10-22T19:53:05.113009Z"
    }
   },
   "cell_type": "code",
   "source": [
    "document_page_sample_1 = scrape_html_2(url_sample_1)\n",
    "\n",
    "with open(f'{path}/{filename_sample_1}', 'w', encoding='utf8', newline='\\n') as file:\n",
    "    file.write(document_page_sample_1)"
   ],
   "id": "2f620c85cfc3f6bb",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T19:53:35.138590Z",
     "start_time": "2025-10-22T19:53:21.286657Z"
    }
   },
   "cell_type": "code",
   "source": [
    "document_page_sample_11 = scrape_html_2(url_sample_11)\n",
    "\n",
    "with open(f'{path}/{filename_sample_11}', 'w', encoding='utf8', newline='\\n') as file:\n",
    "    file.write(document_page_sample_11)"
   ],
   "id": "61e0c70d0ef293d5",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T19:53:51.222379Z",
     "start_time": "2025-10-22T19:53:37.574014Z"
    }
   },
   "cell_type": "code",
   "source": [
    "document_page_sample_12 = scrape_html_2(url_sample_12)\n",
    "\n",
    "with open(f'{path}/{filename_sample_12}', 'w', encoding='utf8', newline='\\n') as file:\n",
    "    file.write(document_page_sample_12)"
   ],
   "id": "4c320d2ab5fd9b34",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T19:54:06.983107Z",
     "start_time": "2025-10-22T19:53:52.647901Z"
    }
   },
   "cell_type": "code",
   "source": [
    "document_page_sample_2 = scrape_html_2(url_sample_2)\n",
    "\n",
    "with open(f'{path}/{filename_sample_2}', 'w', encoding='utf8', newline='\\n') as file:\n",
    "    file.write(document_page_sample_2)"
   ],
   "id": "917333577de10415",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T19:54:24.610315Z",
     "start_time": "2025-10-22T19:54:11.117664Z"
    }
   },
   "cell_type": "code",
   "source": [
    "document_page_sample_21 = scrape_html_2(url_sample_21)\n",
    "\n",
    "with open(f'{path}/{filename_sample_21}', 'w', encoding='utf8', newline='\\n') as file:\n",
    "    file.write(document_page_sample_21)"
   ],
   "id": "27e2b78143faa44c",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T19:54:40.751600Z",
     "start_time": "2025-10-22T19:54:26.535955Z"
    }
   },
   "cell_type": "code",
   "source": [
    "document_page_sample_22 = scrape_html_2(url_sample_22)\n",
    "\n",
    "with open(f'{path}/{filename_sample_22}', 'w', encoding='utf8', newline='\\n') as file:\n",
    "    file.write(document_page_sample_22)"
   ],
   "id": "9ee4c1e0f439e73c",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Scraping the post metadata",
   "id": "ce8f1e3044571085"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T22:50:50.734757Z",
     "start_time": "2025-10-22T22:50:50.730386Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def scrape_posts(source, index_page_url_1, index_page_url_2, start_page, end_page):\n",
    "    \"\"\"Iterates over a set of index pages and extracts post metadata.\"\"\"\n",
    "    data = []\n",
    "\n",
    "    for i in tqdm(range(start_page, end_page + 1)):\n",
    "        url = f\"{index_page_url_1}{i}{index_page_url_2}\"\n",
    "\n",
    "        index_page = scrape_html_2(url)\n",
    "\n",
    "        # Parse page source with BeautifulSoup\n",
    "        soup = BeautifulSoup(index_page, 'lxml')\n",
    "\n",
    "        # Capture the list of items\n",
    "        list_items = soup.find('ul', class_='w-full divide-solid divide-y divide-stroke-muted')\n",
    "\n",
    "        # Extract the items\n",
    "        if list_items:\n",
    "            items = list_items.find_all('li', class_='flex flex-col-reverse first:pt-0 last:pb-0 only:py-0 py-lg md:grid md:grid-cols-12 gap-x-grid-gutter')\n",
    "\n",
    "        for item in items:\n",
    "            # Defaults for robust assignment\n",
    "            title_text = ''\n",
    "            post_url = ''\n",
    "            post_date_time = ''\n",
    "\n",
    "            # Extract the item anchor\n",
    "            anchor = item.find('a', class_='group hocus:text-foreground-accent hocus:theme-dark:text-foreground-td flex gap-2 justify-between items-start theme-focus-outline')\n",
    "\n",
    "            # Extract the title\n",
    "            title_text = ' '.join(anchor.get_text(' ', strip=True).split()) if anchor else ''\n",
    "\n",
    "            # Extract the post URL\n",
    "            if anchor:\n",
    "                post_url = f\"https://www.worldwildlife.org{anchor['href']}\" if anchor.has_attr('href') else ''\n",
    "\n",
    "            # Extract the item time\n",
    "            time_tag = item.find('time')\n",
    "\n",
    "            # Extract post date\n",
    "            post_date_time = time_tag['datetime'] if (time_tag and time_tag.has_attr('datetime')) else ''\n",
    "\n",
    "            # Append the extracted data\n",
    "            data.append({\n",
    "                'Source': source,\n",
    "                'Title': title_text,\n",
    "                'Post URL': post_url,\n",
    "                'Post Date': post_date_time\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(data)"
   ],
   "id": "f4dd5524c0264aed",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T22:50:56.943851Z",
     "start_time": "2025-10-22T22:50:56.939839Z"
    }
   },
   "cell_type": "code",
   "source": [
    "source = 'WWF'\n",
    "index_page_url_1 = 'https://www.worldwildlife.org/news/stories/?page='\n",
    "index_page_url_2 = ''\n",
    "start_page = 1\n",
    "end_page = 41"
   ],
   "id": "dfb46ebd5ca2f9d5",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Note: On 22/10/2025, when the data was extracted, the end page was 41.",
   "id": "708c99fa308f2281"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T23:03:43.660332Z",
     "start_time": "2025-10-22T22:53:28.655811Z"
    }
   },
   "cell_type": "code",
   "source": "df_wwf = scrape_posts(source, index_page_url_1, index_page_url_2, start_page, end_page)",
   "id": "bd69829e22566c6e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [10:14<00:00, 15.00s/it]\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T23:03:55.174767Z",
     "start_time": "2025-10-22T23:03:55.161192Z"
    }
   },
   "cell_type": "code",
   "source": "df_wwf",
   "id": "f57289f1b5dcddf0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    Source                                              Title  \\\n",
       "0      WWF                     Small steps to stop food waste   \n",
       "1      WWF  eDNA reveals snow leopard presence in Bhutan’s...   \n",
       "2      WWF  97% of migratory fish are going extinct. Swimw...   \n",
       "3      WWF  A proposed mine in Alaska threatens a rare pop...   \n",
       "4      WWF  In Indonesia, a researcher sets off to count B...   \n",
       "..     ...                                                ...   \n",
       "401    WWF  The return of a relative: tribal communities i...   \n",
       "402    WWF  With climate change, mangroves bring massive b...   \n",
       "403    WWF                                Food waste warriors   \n",
       "404    WWF    Welcome home! Bison released into new territory   \n",
       "405    WWF  Our oceans are haunted by ghost nets: Why that...   \n",
       "\n",
       "                                              Post URL   Post Date  \n",
       "0    https://www.worldwildlife.org/news/stories/sma...  2025-10-21  \n",
       "1    https://www.worldwildlife.org/news/stories/edn...  2025-10-20  \n",
       "2    https://www.worldwildlife.org/news/stories/97-...              \n",
       "3    https://www.worldwildlife.org/news/stories/a-p...              \n",
       "4    https://www.worldwildlife.org/news/stories/in-...              \n",
       "..                                                 ...         ...  \n",
       "401  https://www.worldwildlife.org/news/stories/the...  2019-11-19  \n",
       "402  https://www.worldwildlife.org/news/stories/wit...  2019-11-07  \n",
       "403  https://www.worldwildlife.org/news/stories/foo...  2019-11-07  \n",
       "404  https://www.worldwildlife.org/news/stories/wel...  2019-10-11  \n",
       "405  https://www.worldwildlife.org/news/stories/our...  2019-07-10  \n",
       "\n",
       "[406 rows x 4 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Title</th>\n",
       "      <th>Post URL</th>\n",
       "      <th>Post Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WWF</td>\n",
       "      <td>Small steps to stop food waste</td>\n",
       "      <td>https://www.worldwildlife.org/news/stories/sma...</td>\n",
       "      <td>2025-10-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WWF</td>\n",
       "      <td>eDNA reveals snow leopard presence in Bhutan’s...</td>\n",
       "      <td>https://www.worldwildlife.org/news/stories/edn...</td>\n",
       "      <td>2025-10-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WWF</td>\n",
       "      <td>97% of migratory fish are going extinct. Swimw...</td>\n",
       "      <td>https://www.worldwildlife.org/news/stories/97-...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WWF</td>\n",
       "      <td>A proposed mine in Alaska threatens a rare pop...</td>\n",
       "      <td>https://www.worldwildlife.org/news/stories/a-p...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WWF</td>\n",
       "      <td>In Indonesia, a researcher sets off to count B...</td>\n",
       "      <td>https://www.worldwildlife.org/news/stories/in-...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>WWF</td>\n",
       "      <td>The return of a relative: tribal communities i...</td>\n",
       "      <td>https://www.worldwildlife.org/news/stories/the...</td>\n",
       "      <td>2019-11-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>WWF</td>\n",
       "      <td>With climate change, mangroves bring massive b...</td>\n",
       "      <td>https://www.worldwildlife.org/news/stories/wit...</td>\n",
       "      <td>2019-11-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>WWF</td>\n",
       "      <td>Food waste warriors</td>\n",
       "      <td>https://www.worldwildlife.org/news/stories/foo...</td>\n",
       "      <td>2019-11-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>WWF</td>\n",
       "      <td>Welcome home! Bison released into new territory</td>\n",
       "      <td>https://www.worldwildlife.org/news/stories/wel...</td>\n",
       "      <td>2019-10-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>WWF</td>\n",
       "      <td>Our oceans are haunted by ghost nets: Why that...</td>\n",
       "      <td>https://www.worldwildlife.org/news/stories/our...</td>\n",
       "      <td>2019-07-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>406 rows × 4 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T23:04:04.310369Z",
     "start_time": "2025-10-22T23:04:04.306540Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Drop rows where 'Post Date' is an empty string\n",
    "df_wwf = df_wwf[df_wwf['Post Date'] != ''].copy()"
   ],
   "id": "8c88951be36f89c6",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T23:04:10.286679Z",
     "start_time": "2025-10-22T23:04:10.281362Z"
    }
   },
   "cell_type": "code",
   "source": "df_wwf['Post Date'] = pd.to_datetime(df_wwf['Post Date'], errors='coerce', utc=True)",
   "id": "fcb4cc652c25267f",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T23:04:13.642812Z",
     "start_time": "2025-10-22T23:04:13.638450Z"
    }
   },
   "cell_type": "code",
   "source": "df_wwf['Post ID'] = id + df_wwf.index.astype(str).str.zfill(6)",
   "id": "91de42f8ee689c15",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T23:04:15.882241Z",
     "start_time": "2025-10-22T23:04:15.877422Z"
    }
   },
   "cell_type": "code",
   "source": "df_wwf.dtypes",
   "id": "128ce35e1d7213c5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Source                    object\n",
       "Title                     object\n",
       "Post URL                  object\n",
       "Post Date    datetime64[ns, UTC]\n",
       "Post ID                   object\n",
       "dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T23:04:21.443106Z",
     "start_time": "2025-10-22T23:04:21.433988Z"
    }
   },
   "cell_type": "code",
   "source": "df_wwf",
   "id": "2866052d4a337c22",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    Source                                              Title  \\\n",
       "0      WWF                     Small steps to stop food waste   \n",
       "1      WWF  eDNA reveals snow leopard presence in Bhutan’s...   \n",
       "6      WWF  Managing North America’s largest Native-owned ...   \n",
       "13     WWF  Nature, resilience, finance: Three words that ...   \n",
       "14     WWF               Transforming thermal energy for good   \n",
       "..     ...                                                ...   \n",
       "401    WWF  The return of a relative: tribal communities i...   \n",
       "402    WWF  With climate change, mangroves bring massive b...   \n",
       "403    WWF                                Food waste warriors   \n",
       "404    WWF    Welcome home! Bison released into new territory   \n",
       "405    WWF  Our oceans are haunted by ghost nets: Why that...   \n",
       "\n",
       "                                              Post URL  \\\n",
       "0    https://www.worldwildlife.org/news/stories/sma...   \n",
       "1    https://www.worldwildlife.org/news/stories/edn...   \n",
       "6    https://www.worldwildlife.org/news/stories/man...   \n",
       "13   https://www.worldwildlife.org/news/stories/nat...   \n",
       "14   https://www.worldwildlife.org/news/stories/tra...   \n",
       "..                                                 ...   \n",
       "401  https://www.worldwildlife.org/news/stories/the...   \n",
       "402  https://www.worldwildlife.org/news/stories/wit...   \n",
       "403  https://www.worldwildlife.org/news/stories/foo...   \n",
       "404  https://www.worldwildlife.org/news/stories/wel...   \n",
       "405  https://www.worldwildlife.org/news/stories/our...   \n",
       "\n",
       "                    Post Date    Post ID  \n",
       "0   2025-10-21 00:00:00+00:00  wwf000000  \n",
       "1   2025-10-20 00:00:00+00:00  wwf000001  \n",
       "6   2025-10-09 00:00:00+00:00  wwf000006  \n",
       "13  2025-10-01 00:00:00+00:00  wwf000013  \n",
       "14  2025-09-30 00:00:00+00:00  wwf000014  \n",
       "..                        ...        ...  \n",
       "401 2019-11-19 00:00:00+00:00  wwf000401  \n",
       "402 2019-11-07 00:00:00+00:00  wwf000402  \n",
       "403 2019-11-07 00:00:00+00:00  wwf000403  \n",
       "404 2019-10-11 00:00:00+00:00  wwf000404  \n",
       "405 2019-07-10 00:00:00+00:00  wwf000405  \n",
       "\n",
       "[377 rows x 5 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Title</th>\n",
       "      <th>Post URL</th>\n",
       "      <th>Post Date</th>\n",
       "      <th>Post ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WWF</td>\n",
       "      <td>Small steps to stop food waste</td>\n",
       "      <td>https://www.worldwildlife.org/news/stories/sma...</td>\n",
       "      <td>2025-10-21 00:00:00+00:00</td>\n",
       "      <td>wwf000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WWF</td>\n",
       "      <td>eDNA reveals snow leopard presence in Bhutan’s...</td>\n",
       "      <td>https://www.worldwildlife.org/news/stories/edn...</td>\n",
       "      <td>2025-10-20 00:00:00+00:00</td>\n",
       "      <td>wwf000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>WWF</td>\n",
       "      <td>Managing North America’s largest Native-owned ...</td>\n",
       "      <td>https://www.worldwildlife.org/news/stories/man...</td>\n",
       "      <td>2025-10-09 00:00:00+00:00</td>\n",
       "      <td>wwf000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>WWF</td>\n",
       "      <td>Nature, resilience, finance: Three words that ...</td>\n",
       "      <td>https://www.worldwildlife.org/news/stories/nat...</td>\n",
       "      <td>2025-10-01 00:00:00+00:00</td>\n",
       "      <td>wwf000013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>WWF</td>\n",
       "      <td>Transforming thermal energy for good</td>\n",
       "      <td>https://www.worldwildlife.org/news/stories/tra...</td>\n",
       "      <td>2025-09-30 00:00:00+00:00</td>\n",
       "      <td>wwf000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>WWF</td>\n",
       "      <td>The return of a relative: tribal communities i...</td>\n",
       "      <td>https://www.worldwildlife.org/news/stories/the...</td>\n",
       "      <td>2019-11-19 00:00:00+00:00</td>\n",
       "      <td>wwf000401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>WWF</td>\n",
       "      <td>With climate change, mangroves bring massive b...</td>\n",
       "      <td>https://www.worldwildlife.org/news/stories/wit...</td>\n",
       "      <td>2019-11-07 00:00:00+00:00</td>\n",
       "      <td>wwf000402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>WWF</td>\n",
       "      <td>Food waste warriors</td>\n",
       "      <td>https://www.worldwildlife.org/news/stories/foo...</td>\n",
       "      <td>2019-11-07 00:00:00+00:00</td>\n",
       "      <td>wwf000403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>WWF</td>\n",
       "      <td>Welcome home! Bison released into new territory</td>\n",
       "      <td>https://www.worldwildlife.org/news/stories/wel...</td>\n",
       "      <td>2019-10-11 00:00:00+00:00</td>\n",
       "      <td>wwf000404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>WWF</td>\n",
       "      <td>Our oceans are haunted by ghost nets: Why that...</td>\n",
       "      <td>https://www.worldwildlife.org/news/stories/our...</td>\n",
       "      <td>2019-07-10 00:00:00+00:00</td>\n",
       "      <td>wwf000405</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>377 rows × 5 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Export to a file",
   "id": "97d834b71ea2537a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T23:04:40.485900Z",
     "start_time": "2025-10-22T23:04:40.479233Z"
    }
   },
   "cell_type": "code",
   "source": "df_wwf.to_json(f\"{output_directory}/{dataset_filename_1}.jsonl\", orient='records', lines=True)",
   "id": "bdfff1031bf65903",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Scrape the posts",
   "id": "a12745e6724b2c5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Import the data into a DataFrame",
   "id": "a34d7fc5754270d7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T23:04:46.319371Z",
     "start_time": "2025-10-22T23:04:46.310542Z"
    }
   },
   "cell_type": "code",
   "source": "df_wwf = pd.read_json(f\"{input_directory}/{dataset_filename_1}.jsonl\", lines=True)",
   "id": "54e0ed3f0e64353f",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T23:04:50.499292Z",
     "start_time": "2025-10-22T23:04:50.494892Z"
    }
   },
   "cell_type": "code",
   "source": "df_wwf['Post Date'] = pd.to_datetime(df_wwf['Post Date'], unit='ms')",
   "id": "15ce35574802409d",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Scrape the posts",
   "id": "4b8f293b1ce280c8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T00:39:47.689390Z",
     "start_time": "2025-10-22T23:05:00.929545Z"
    }
   },
   "cell_type": "code",
   "source": "scrape_html_docs_2(df_wwf, path)",
   "id": "af54d56e1b11a4e0",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping HTML documents: 100%|██████████| 377/377 [1:34:46<00:00, 15.08s/it]\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Extract the text from the posts",
   "id": "34e40ccc9148a10d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T23:01:39.065596Z",
     "start_time": "2025-10-01T23:01:39.056650Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_text(df, path):\n",
    "    \"\"\"Extracts text from HTML files and saves as text files.\"\"\"\n",
    "\n",
    "    for post_id in df['Post ID']:\n",
    "        html_file = os.path.join(path, f\"{post_id}.html\")\n",
    "        txt_file = os.path.join(path, f\"{post_id}.txt\")\n",
    "\n",
    "        # Check if the HTML file exists\n",
    "        if not os.path.exists(html_file):\n",
    "            logging.error(f\"Skipping {html_file}: File not found\")\n",
    "            continue\n",
    "\n",
    "        # Read HTML content\n",
    "        with open(html_file, 'r', encoding='utf-8') as file:\n",
    "            soup = BeautifulSoup(file, 'lxml')\n",
    "\n",
    "        # Initialise text variable\n",
    "        text = ''\n",
    "\n",
    "        # Web Scraping - Begin\n",
    "\n",
    "        # Capture the 'article body'\n",
    "        post_body = soup.find('div', id='content')\n",
    "\n",
    "        # Extract the authors\n",
    "        if post_body:\n",
    "            author_li = post_body.find('li', class_='span4 gutter-horiz-in')\n",
    "            if author_li:\n",
    "                author_name = ' '.join(author_li.get_text(' ', strip=True).replace('Author:', '').split()) if author_li else ''\n",
    "                text += f\"Author: {author_name}\\n\"\n",
    "\n",
    "        # Extract the paragraphs\n",
    "        if post_body:\n",
    "            post_contents = post_body.find('div', class_='row gutter-horiz-in wysiwyg lead')\n",
    "            if post_contents:\n",
    "                for post_content in post_contents:\n",
    "                    # Ensure the item is a Tag, not a NavigableString or other types\n",
    "                    if not hasattr(post_content, 'find_all'):\n",
    "                        continue\n",
    "                    for block in post_content.find_all(['p', 'ul', 'ol'], recursive=False):\n",
    "                        if block.name == 'p':\n",
    "                            paragraph_text = ' '.join(block.get_text(' ', strip=True).split())\n",
    "                            text += f\"{paragraph_text}\\n\"\n",
    "                        elif block.name in ('ul', 'ol'):\n",
    "                            # Capture top-level list items in order\n",
    "                            for li in block.find_all('li', recursive=False):\n",
    "                                li_text = ' '.join(li.get_text(' ', strip=True).split())\n",
    "                                text += f\"{li_text}\\n\"\n",
    "\n",
    "        # Extract the paragraphs\n",
    "        if post_body:\n",
    "            post_contents = post_body.find_all('div', class_='gutter-horiz-in wysiwyg')\n",
    "            if post_contents:\n",
    "                for post_content in post_contents:\n",
    "                    # Ensure the item is a Tag, not a NavigableString or other types\n",
    "                    if not hasattr(post_content, 'find_all'):\n",
    "                        continue\n",
    "                    for block in post_content.find_all(['p', 'ul', 'ol'], recursive=False):\n",
    "                        if block.name == 'p':\n",
    "                            paragraph_text = ' '.join(block.get_text(' ', strip=True).split())\n",
    "                            text += f\"{paragraph_text}\\n\"\n",
    "                        elif block.name in ('ul', 'ol'):\n",
    "                            # Capture top-level list items in order\n",
    "                            for li in block.find_all('li', recursive=False):\n",
    "                                li_text = ' '.join(li.get_text(' ', strip=True).split())\n",
    "                                text += f\"{li_text}\\n\"\n",
    "\n",
    "        # Web Scraping - End\n",
    "\n",
    "        # Save text to a text file\n",
    "        with open(txt_file, 'w', encoding='utf-8', newline='\\n') as file:\n",
    "            file.write(text)\n",
    "\n",
    "        logging.info(f\"Saved text for {post_id} to {txt_file}\")"
   ],
   "id": "7677cb6bc9ba61e0",
   "outputs": [],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T22:57:43.968593Z",
     "start_time": "2025-10-01T22:57:43.956888Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_text(df, path):\n",
    "    \"\"\"Extracts text from HTML files and saves as text files.\"\"\"\n",
    "\n",
    "    for post_id in df['Post ID']:\n",
    "        html_file = os.path.join(path, f\"{post_id}.html\")\n",
    "        txt_file = os.path.join(path, f\"{post_id}.txt\")\n",
    "\n",
    "        # Check if the HTML file exists\n",
    "        if not os.path.exists(html_file):\n",
    "            logging.error(f\"Skipping {html_file}: File not found\")\n",
    "            continue\n",
    "\n",
    "        # Read HTML content\n",
    "        with open(html_file, 'r', encoding='utf-8') as file:\n",
    "            soup = BeautifulSoup(file, 'lxml')\n",
    "\n",
    "        # Initialize text variable\n",
    "        text = ''\n",
    "\n",
    "        # Capture the 'post body'\n",
    "        post_body = soup.find('body')\n",
    "\n",
    "        # Extract content from both div classes and combine the results\n",
    "        if post_body:\n",
    "            content_sources = []\n",
    "            # Look for content in 'row gutter-horiz-in wysiwyg lead'\n",
    "            first_set = post_body.find('div', class_='row gutter-horiz-in wysiwyg lead')\n",
    "            if first_set:\n",
    "                content_sources.append(first_set)\n",
    "\n",
    "            # Look for content in 'gutter-horiz-in wysiwyg'\n",
    "            second_set = post_body.find_all('div', class_='gutter-horiz-in wysiwyg')\n",
    "            if second_set:\n",
    "                content_sources.append(second_set)\n",
    "\n",
    "            # Iterate over all collected content sources\n",
    "            for content in content_sources:\n",
    "                for post_content in content:\n",
    "                    # Ensure the item is a Tag and not another type\n",
    "                    if not hasattr(post_content, 'find_all'):\n",
    "                        continue\n",
    "                    ## Extract and clean the text from the content\n",
    "                    #paragraph_text = ' '.join(post_content.get_text(' ', strip=True).split())\n",
    "                    #text += f\"{paragraph_text}\\n\"\n",
    "\n",
    "                    for block in post_content.find_all(['p', 'ul', 'ol'], recursive=False):\n",
    "                        if block.name == 'p':\n",
    "                            paragraph_text = ' '.join(block.get_text(' ', strip=True).split())\n",
    "                            text += f\"{paragraph_text}\\n\"\n",
    "                        elif block.name in ('ul', 'ol'):\n",
    "                            # Capture top-level list items in order\n",
    "                            for li in block.find_all('li', recursive=False):\n",
    "                                li_text = ' '.join(li.get_text(' ', strip=True).split())\n",
    "                                text += f\"{li_text}\\n\"\n",
    "\n",
    "        else:\n",
    "            logging.warning(f\"No body tag found in {html_file}\")\n",
    "\n",
    "        # Save text to a text file\n",
    "        if text:\n",
    "            with open(txt_file, 'w', encoding='utf-8', newline='\\n') as file:\n",
    "                file.write(text)\n",
    "            logging.info(f\"Saved text for {post_id} to {txt_file}\")\n",
    "        else:\n",
    "            logging.warning(f\"No content extracted for {html_file}\")"
   ],
   "id": "39df5f37a0bff168",
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T23:01:47.433955Z",
     "start_time": "2025-10-01T23:01:44.142726Z"
    }
   },
   "cell_type": "code",
   "source": "extract_text(df_wwf, path)",
   "id": "94288093d720a41",
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Break down the texts into paragraphs",
   "id": "996e6004ebdc2e1b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T14:28:59.038323Z",
     "start_time": "2025-08-19T14:28:57.783687Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 23,
   "source": [
    "# Prepare to collect rows\n",
    "data = []\n",
    "\n",
    "# Loop through each 'Post ID' in the DataFrame\n",
    "for _, row in df_grp.iterrows():\n",
    "    post_id = row['Post ID']\n",
    "\n",
    "    paragraph_count = 0\n",
    "    file_path = os.path.join(path, f\"{post_id}.txt\")\n",
    "\n",
    "    if not os.path.isfile(file_path):\n",
    "        print(f\"Missing file: {file_path}\")\n",
    "        continue\n",
    "\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            line = ' '.join(line.split()).strip()\n",
    "            if not line:\n",
    "                continue\n",
    "\n",
    "            if line.startswith('Category:'):\n",
    "                category_name = line.partition(':')[2].strip()\n",
    "                # If a category line is blank or only has the colon, we gracefully assign the fallback name 'Undefined Category'\n",
    "                category = category_name if category_name else 'Undefined Category'\n",
    "                paragraph_count = 0 # Resetting paragraph count for new category\n",
    "\n",
    "            elif line:\n",
    "                paragraph_count += 1\n",
    "                data.append({\n",
    "                    'Post ID': post_id,\n",
    "                    'Category': category,\n",
    "                    'Paragraph': f\"Paragraph {paragraph_count}\",\n",
    "                    'Text Paragraph': line\n",
    "                    })\n",
    "\n",
    "# Create final DataFrame\n",
    "df_paragraph = pd.DataFrame(data)"
   ],
   "id": "c18cf8a2fe6442de"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T14:29:02.524843Z",
     "start_time": "2025-08-19T14:29:02.514275Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         Post ID    Category     Paragraph  \\\n",
       "0      grp000000  Greenpeace   Paragraph 1   \n",
       "1      grp000000  Greenpeace   Paragraph 2   \n",
       "2      grp000000  Greenpeace   Paragraph 3   \n",
       "3      grp000000  Greenpeace   Paragraph 4   \n",
       "4      grp000000  Greenpeace   Paragraph 5   \n",
       "...          ...         ...           ...   \n",
       "23415  grp001356  Greenpeace  Paragraph 13   \n",
       "23416  grp001356  Greenpeace  Paragraph 14   \n",
       "23417  grp001356  Greenpeace  Paragraph 15   \n",
       "23418  grp001356  Greenpeace  Paragraph 16   \n",
       "23419  grp001356  Greenpeace  Paragraph 17   \n",
       "\n",
       "                                          Text Paragraph  \n",
       "0      From a banner protest at the plastic treaty in...  \n",
       "1      🇬🇧 England – Greenpeace UK’s climbers install ...  \n",
       "2      After securing a giant 12m x 8m canvas to one ...  \n",
       "3      The work starkly visualises the wound inflicte...  \n",
       "4      🇨🇭 Switzerland – Juan Carlos Monterrey Gómez, ...  \n",
       "...                                                  ...  \n",
       "23415  He joined Toronto’s City TV as an ecology spec...  \n",
       "23416  Over the years he continued to contribute to G...  \n",
       "23417  In a recent book, Rex Weyler writes about refl...  \n",
       "23418  “The ironies and tension of history simultaneo...  \n",
       "23419  Bob Hunter made much of his opportunity to ser...  \n",
       "\n",
       "[23420 rows x 4 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Post ID</th>\n",
       "      <th>Category</th>\n",
       "      <th>Paragraph</th>\n",
       "      <th>Text Paragraph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>grp000000</td>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Paragraph 1</td>\n",
       "      <td>From a banner protest at the plastic treaty in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>grp000000</td>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Paragraph 2</td>\n",
       "      <td>🇬🇧 England – Greenpeace UK’s climbers install ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>grp000000</td>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Paragraph 3</td>\n",
       "      <td>After securing a giant 12m x 8m canvas to one ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>grp000000</td>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Paragraph 4</td>\n",
       "      <td>The work starkly visualises the wound inflicte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>grp000000</td>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Paragraph 5</td>\n",
       "      <td>🇨🇭 Switzerland – Juan Carlos Monterrey Gómez, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23415</th>\n",
       "      <td>grp001356</td>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Paragraph 13</td>\n",
       "      <td>He joined Toronto’s City TV as an ecology spec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23416</th>\n",
       "      <td>grp001356</td>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Paragraph 14</td>\n",
       "      <td>Over the years he continued to contribute to G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23417</th>\n",
       "      <td>grp001356</td>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Paragraph 15</td>\n",
       "      <td>In a recent book, Rex Weyler writes about refl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23418</th>\n",
       "      <td>grp001356</td>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Paragraph 16</td>\n",
       "      <td>“The ironies and tension of history simultaneo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23419</th>\n",
       "      <td>grp001356</td>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Paragraph 17</td>\n",
       "      <td>Bob Hunter made much of his opportunity to ser...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23420 rows × 4 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24,
   "source": "df_paragraph",
   "id": "b79dd5103e5c20b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Merge `df_grp` into `df_paragraph` to obtain `df_grp_paragraph`",
   "id": "4bc8debd85366ed1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T14:29:06.346979Z",
     "start_time": "2025-08-19T14:29:06.326312Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 25,
   "source": "df_grp_paragraph = df_grp.merge(df_paragraph, on='Post ID', how='left')",
   "id": "cec4a58b6ac4c437"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T14:29:10.735175Z",
     "start_time": "2025-08-19T14:29:10.720509Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "           Source Post Term         Post Tags  \\\n",
       "0      Greenpeace   Stories       Photography   \n",
       "1      Greenpeace   Stories       Photography   \n",
       "2      Greenpeace   Stories       Photography   \n",
       "3      Greenpeace   Stories       Photography   \n",
       "4      Greenpeace   Stories       Photography   \n",
       "...           ...       ...               ...   \n",
       "23415  Greenpeace   Stories  AboutUs, 50Years   \n",
       "23416  Greenpeace   Stories  AboutUs, 50Years   \n",
       "23417  Greenpeace   Stories  AboutUs, 50Years   \n",
       "23418  Greenpeace   Stories  AboutUs, 50Years   \n",
       "23419  Greenpeace   Stories  AboutUs, 50Years   \n",
       "\n",
       "                                 Title  \\\n",
       "0      Greenpeace Pictures of the Week   \n",
       "1      Greenpeace Pictures of the Week   \n",
       "2      Greenpeace Pictures of the Week   \n",
       "3      Greenpeace Pictures of the Week   \n",
       "4      Greenpeace Pictures of the Week   \n",
       "...                                ...   \n",
       "23415           Bob Hunter 1941 – 2005   \n",
       "23416           Bob Hunter 1941 – 2005   \n",
       "23417           Bob Hunter 1941 – 2005   \n",
       "23418           Bob Hunter 1941 – 2005   \n",
       "23419           Bob Hunter 1941 – 2005   \n",
       "\n",
       "                                                Post URL  \\\n",
       "0      https://www.greenpeace.org/international/story...   \n",
       "1      https://www.greenpeace.org/international/story...   \n",
       "2      https://www.greenpeace.org/international/story...   \n",
       "3      https://www.greenpeace.org/international/story...   \n",
       "4      https://www.greenpeace.org/international/story...   \n",
       "...                                                  ...   \n",
       "23415  https://www.greenpeace.org/international/story...   \n",
       "23416  https://www.greenpeace.org/international/story...   \n",
       "23417  https://www.greenpeace.org/international/story...   \n",
       "23418  https://www.greenpeace.org/international/story...   \n",
       "23419  https://www.greenpeace.org/international/story...   \n",
       "\n",
       "                        Authors           Post Date    Post ID    Category  \\\n",
       "0      Greenpeace International 2025-08-15 01:45:33  grp000000  Greenpeace   \n",
       "1      Greenpeace International 2025-08-15 01:45:33  grp000000  Greenpeace   \n",
       "2      Greenpeace International 2025-08-15 01:45:33  grp000000  Greenpeace   \n",
       "3      Greenpeace International 2025-08-15 01:45:33  grp000000  Greenpeace   \n",
       "4      Greenpeace International 2025-08-15 01:45:33  grp000000  Greenpeace   \n",
       "...                         ...                 ...        ...         ...   \n",
       "23415  Greenpeace International 2005-05-02 15:15:00  grp001356  Greenpeace   \n",
       "23416  Greenpeace International 2005-05-02 15:15:00  grp001356  Greenpeace   \n",
       "23417  Greenpeace International 2005-05-02 15:15:00  grp001356  Greenpeace   \n",
       "23418  Greenpeace International 2005-05-02 15:15:00  grp001356  Greenpeace   \n",
       "23419  Greenpeace International 2005-05-02 15:15:00  grp001356  Greenpeace   \n",
       "\n",
       "          Paragraph                                     Text Paragraph  \n",
       "0       Paragraph 1  From a banner protest at the plastic treaty in...  \n",
       "1       Paragraph 2  🇬🇧 England – Greenpeace UK’s climbers install ...  \n",
       "2       Paragraph 3  After securing a giant 12m x 8m canvas to one ...  \n",
       "3       Paragraph 4  The work starkly visualises the wound inflicte...  \n",
       "4       Paragraph 5  🇨🇭 Switzerland – Juan Carlos Monterrey Gómez, ...  \n",
       "...             ...                                                ...  \n",
       "23415  Paragraph 13  He joined Toronto’s City TV as an ecology spec...  \n",
       "23416  Paragraph 14  Over the years he continued to contribute to G...  \n",
       "23417  Paragraph 15  In a recent book, Rex Weyler writes about refl...  \n",
       "23418  Paragraph 16  “The ironies and tension of history simultaneo...  \n",
       "23419  Paragraph 17  Bob Hunter made much of his opportunity to ser...  \n",
       "\n",
       "[23420 rows x 11 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Post Term</th>\n",
       "      <th>Post Tags</th>\n",
       "      <th>Title</th>\n",
       "      <th>Post URL</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Post Date</th>\n",
       "      <th>Post ID</th>\n",
       "      <th>Category</th>\n",
       "      <th>Paragraph</th>\n",
       "      <th>Text Paragraph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Stories</td>\n",
       "      <td>Photography</td>\n",
       "      <td>Greenpeace Pictures of the Week</td>\n",
       "      <td>https://www.greenpeace.org/international/story...</td>\n",
       "      <td>Greenpeace International</td>\n",
       "      <td>2025-08-15 01:45:33</td>\n",
       "      <td>grp000000</td>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Paragraph 1</td>\n",
       "      <td>From a banner protest at the plastic treaty in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Stories</td>\n",
       "      <td>Photography</td>\n",
       "      <td>Greenpeace Pictures of the Week</td>\n",
       "      <td>https://www.greenpeace.org/international/story...</td>\n",
       "      <td>Greenpeace International</td>\n",
       "      <td>2025-08-15 01:45:33</td>\n",
       "      <td>grp000000</td>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Paragraph 2</td>\n",
       "      <td>🇬🇧 England – Greenpeace UK’s climbers install ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Stories</td>\n",
       "      <td>Photography</td>\n",
       "      <td>Greenpeace Pictures of the Week</td>\n",
       "      <td>https://www.greenpeace.org/international/story...</td>\n",
       "      <td>Greenpeace International</td>\n",
       "      <td>2025-08-15 01:45:33</td>\n",
       "      <td>grp000000</td>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Paragraph 3</td>\n",
       "      <td>After securing a giant 12m x 8m canvas to one ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Stories</td>\n",
       "      <td>Photography</td>\n",
       "      <td>Greenpeace Pictures of the Week</td>\n",
       "      <td>https://www.greenpeace.org/international/story...</td>\n",
       "      <td>Greenpeace International</td>\n",
       "      <td>2025-08-15 01:45:33</td>\n",
       "      <td>grp000000</td>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Paragraph 4</td>\n",
       "      <td>The work starkly visualises the wound inflicte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Stories</td>\n",
       "      <td>Photography</td>\n",
       "      <td>Greenpeace Pictures of the Week</td>\n",
       "      <td>https://www.greenpeace.org/international/story...</td>\n",
       "      <td>Greenpeace International</td>\n",
       "      <td>2025-08-15 01:45:33</td>\n",
       "      <td>grp000000</td>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Paragraph 5</td>\n",
       "      <td>🇨🇭 Switzerland – Juan Carlos Monterrey Gómez, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23415</th>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Stories</td>\n",
       "      <td>AboutUs, 50Years</td>\n",
       "      <td>Bob Hunter 1941 – 2005</td>\n",
       "      <td>https://www.greenpeace.org/international/story...</td>\n",
       "      <td>Greenpeace International</td>\n",
       "      <td>2005-05-02 15:15:00</td>\n",
       "      <td>grp001356</td>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Paragraph 13</td>\n",
       "      <td>He joined Toronto’s City TV as an ecology spec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23416</th>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Stories</td>\n",
       "      <td>AboutUs, 50Years</td>\n",
       "      <td>Bob Hunter 1941 – 2005</td>\n",
       "      <td>https://www.greenpeace.org/international/story...</td>\n",
       "      <td>Greenpeace International</td>\n",
       "      <td>2005-05-02 15:15:00</td>\n",
       "      <td>grp001356</td>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Paragraph 14</td>\n",
       "      <td>Over the years he continued to contribute to G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23417</th>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Stories</td>\n",
       "      <td>AboutUs, 50Years</td>\n",
       "      <td>Bob Hunter 1941 – 2005</td>\n",
       "      <td>https://www.greenpeace.org/international/story...</td>\n",
       "      <td>Greenpeace International</td>\n",
       "      <td>2005-05-02 15:15:00</td>\n",
       "      <td>grp001356</td>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Paragraph 15</td>\n",
       "      <td>In a recent book, Rex Weyler writes about refl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23418</th>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Stories</td>\n",
       "      <td>AboutUs, 50Years</td>\n",
       "      <td>Bob Hunter 1941 – 2005</td>\n",
       "      <td>https://www.greenpeace.org/international/story...</td>\n",
       "      <td>Greenpeace International</td>\n",
       "      <td>2005-05-02 15:15:00</td>\n",
       "      <td>grp001356</td>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Paragraph 16</td>\n",
       "      <td>“The ironies and tension of history simultaneo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23419</th>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Stories</td>\n",
       "      <td>AboutUs, 50Years</td>\n",
       "      <td>Bob Hunter 1941 – 2005</td>\n",
       "      <td>https://www.greenpeace.org/international/story...</td>\n",
       "      <td>Greenpeace International</td>\n",
       "      <td>2005-05-02 15:15:00</td>\n",
       "      <td>grp001356</td>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Paragraph 17</td>\n",
       "      <td>Bob Hunter made much of his opportunity to ser...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23420 rows × 11 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26,
   "source": "df_grp_paragraph",
   "id": "d4cd15de14a15770"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Find texts that are empty",
   "id": "6cb26963b39bb72b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T14:29:19.348541Z",
     "start_time": "2025-08-19T14:29:19.335147Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27,
   "source": [
    "# Find rows where the specified column has empty strings\n",
    "mask = df_grp_paragraph['Category'].isnull()\n",
    "\n",
    "# Get the corresponding 'Post ID' values\n",
    "post_ids_with_missing_text = df_grp_paragraph[mask]['Post ID'].tolist()\n",
    "\n",
    "post_ids_with_missing_text"
   ],
   "id": "f2e1b9cce760c25f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T14:29:28.930674Z",
     "start_time": "2025-08-19T14:29:28.921520Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Source, Post Term, Post Tags, Title, Post URL, Authors, Post Date, Post ID, Category, Paragraph, Text Paragraph]\n",
       "Index: []"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Post Term</th>\n",
       "      <th>Post Tags</th>\n",
       "      <th>Title</th>\n",
       "      <th>Post URL</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Post Date</th>\n",
       "      <th>Post ID</th>\n",
       "      <th>Category</th>\n",
       "      <th>Paragraph</th>\n",
       "      <th>Text Paragraph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28,
   "source": [
    "df_grp_empty = df_grp_paragraph[df_grp_paragraph['Category'].isnull()]\n",
    "df_grp_empty"
   ],
   "id": "2bcaf8d3088670d7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Rescrape",
   "id": "630b4e120bfc1f22"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T01:35:38.108711Z",
     "start_time": "2025-08-19T01:35:24.630809Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping HTML documents: 100%|██████████| 2/2 [00:13<00:00,  6.73s/it]\n"
     ]
    }
   ],
   "execution_count": 40,
   "source": "scrape_html_docs(df_grp_empty, path)",
   "id": "7bb5156cd1635b86"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T14:25:44.620295Z",
     "start_time": "2025-08-19T14:25:44.402131Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 20,
   "source": "extract_text_gp000071_gp001092(df_grp_empty, path)",
   "id": "32521c01e92d3cd3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Export to a file",
   "id": "8713c5a55ca54bbc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T14:29:38.185543Z",
     "start_time": "2025-08-19T14:29:37.920071Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 29,
   "source": "df_grp_paragraph.to_json(f\"{output_directory}/{dataset_filename_2}.jsonl\", orient='records', lines=True)",
   "id": "b14fa46174e4b943"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T14:29:46.595231Z",
     "start_time": "2025-08-19T14:29:40.314615Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 30,
   "source": "df_grp_paragraph.to_excel(f\"{output_directory}/{dataset_filename_2}.xlsx\", index=False)",
   "id": "15df327b9a34d1b9"
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
