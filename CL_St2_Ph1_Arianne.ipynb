{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "810d9f10-ec19-4b09-8f90-e983e460b319",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"https://laelgelcpublic.s3.sa-east-1.amazonaws.com/lael_50_years_narrow_white.png.no_years.400px_96dpi.png\" width=\"300\" alt=\"LAEL 50 years logo\">\n",
    "<h3>APPLIED LINGUISTICS GRADUATE PROGRAMME (LAEL)</h3>\n",
    "</center>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888c2c96-2fc3-4a1a-995b-c388036a2a15",
   "metadata": {},
   "source": [
    "# Corpus Linguistics - Study 2 - Phase 1 - Arianne"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3291bbafe478f3d",
   "metadata": {},
   "source": [
    "This phase aims at extracting text from the blog posts of the following websites:\n",
    "- [Greenpeace Stories](https://www.greenpeace.org/international/story/)\n",
    "- [WWF](https://www.worldwildlife.org/stories?page=1&threat_id=effects-of-climate-change)\n",
    "- [WRI](https://www.wri.org/resources/topic/climate-53/type/insights-50?page=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a685d8b0-7715-45a6-9489-2d3db9b346c8",
   "metadata": {},
   "source": [
    "## Required Python packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e16e73-b1b9-4838-8cce-a29dc300868e",
   "metadata": {},
   "source": [
    "- beautifulsoup4\n",
    "- pandas\n",
    "- tqdm\n",
    "- selenium\n",
    "- lxml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa922755-c4d6-4008-9aad-d35e33b18ed7",
   "metadata": {},
   "source": [
    "## Import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "id": "fe5c4b76ea4f95d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T00:22:22.798280Z",
     "start_time": "2025-08-19T00:22:21.327100Z"
    }
   },
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.edge.service import Service\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.edge.options import Options"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "b1911dcf5a8425df",
   "metadata": {},
   "source": [
    "## Define input variables"
   ]
  },
  {
   "cell_type": "code",
   "id": "ffccb3260540bf52",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T00:22:26.360532Z",
     "start_time": "2025-08-19T00:22:26.356711Z"
    }
   },
   "source": [
    "input_directory = 'cl_st2_ph1_arianne'\n",
    "output_directory = 'cl_st2_ph1_arianne'"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "cb6c223aee4c74b",
   "metadata": {},
   "source": [
    "## Create output directory"
   ]
  },
  {
   "cell_type": "code",
   "id": "3cc952da8ef9ec1f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T00:22:29.666893Z",
     "start_time": "2025-08-19T00:22:29.658133Z"
    }
   },
   "source": [
    "# Check if the output directory already exists. If it does, do nothing. If it doesn't exist, create it.\n",
    "if os.path.exists(output_directory):\n",
    "    print('Output directory already exists.')\n",
    "else:\n",
    "    try:\n",
    "        os.makedirs(output_directory)\n",
    "        print('Output directory successfully created.')\n",
    "    except OSError as e:\n",
    "        print('Failed to create the directory:', e)\n",
    "        sys.exit(1)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output directory already exists.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "d70d1d62f24b7b24",
   "metadata": {},
   "source": [
    "## Set up logging"
   ]
  },
  {
   "cell_type": "code",
   "id": "b3ddac3c2e754a25",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T00:22:33.467220Z",
     "start_time": "2025-08-19T00:22:33.464312Z"
    }
   },
   "source": [
    "log_filename = f\"{output_directory}/{output_directory}.log\""
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "35dcc9ad97a25ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T00:22:35.714286Z",
     "start_time": "2025-08-19T00:22:35.710495Z"
    }
   },
   "source": [
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    filename=log_filename\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "942249a4815dda54",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f0ccb2a4a2d50c",
   "metadata": {},
   "source": [
    "### Create output subdirectories"
   ]
  },
  {
   "cell_type": "code",
   "id": "cdbf413aac1b7b7e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T00:22:40.580084Z",
     "start_time": "2025-08-19T00:22:40.575988Z"
    }
   },
   "source": [
    "def create_directory(path):\n",
    "    \"\"\"Creates a subdirectory if it doesn't exist.\"\"\"\n",
    "    if not os.path.exists(path):\n",
    "        try:\n",
    "            os.makedirs(path)\n",
    "            print(f\"Successfully created the directory: {path}\")\n",
    "        except OSError as e:\n",
    "            print(f\"Failed to create the {path} directory: {e}\")\n",
    "            sys.exit(1)\n",
    "    else:\n",
    "        print(f\"Directory already exists: {path}\")"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "bae051d781151e8e",
   "metadata": {},
   "source": [
    "### Scrape web pages"
   ]
  },
  {
   "cell_type": "code",
   "id": "5d0f699053e28d5b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T00:22:43.551675Z",
     "start_time": "2025-08-19T00:22:43.546114Z"
    }
   },
   "source": [
    "def scrape_html(url):\n",
    "    \"\"\"Loads a web page and returns its source HTML.\"\"\"\n",
    "    # Setting up the WebDriver\n",
    "    #service = Service(r'C:\\Users\\eyamr\\OneDrive\\00-Technology\\msedgedriver\\edgedriver_win64\\msedgedriver.exe')\n",
    "    service = Service('/Users/eyamrog/msedgedriver/edgedriver_mac64/msedgedriver')\n",
    "    #service = Service('/home/eyamrog/msedgedriver/edgedriver_linux64/msedgedriver')\n",
    "\n",
    "    # Configure Edge to run headless\n",
    "    options = Options()\n",
    "    # For modern Edge/Chromium; if incompatible with your version, try \"--headless\"\n",
    "    options.add_argument('--headless=new')\n",
    "    options.add_argument('--disable-gpu')\n",
    "    options.add_argument('--window-size=1920,1080')\n",
    "\n",
    "    driver = webdriver.Edge(service=service, options=options)\n",
    "    html = None\n",
    "    try:\n",
    "        driver.get(url)\n",
    "\n",
    "        # Explicit wait for stable page load\n",
    "        wait = WebDriverWait(driver, 10)\n",
    "        max_wait_time = 30\n",
    "        start_time = time.time()\n",
    "        previous_html = ''\n",
    "\n",
    "        while True:\n",
    "            current_html = driver.page_source\n",
    "            if current_html == previous_html or time.time() - start_time > max_wait_time:\n",
    "                break\n",
    "            previous_html = current_html\n",
    "            time.sleep(2)\n",
    "\n",
    "        html = driver.page_source  # Capture page source\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error scraping {url}: {e}\")\n",
    "    finally:\n",
    "        # Always close WebDriver\n",
    "        driver.quit()\n",
    "\n",
    "    return html"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "9f931a641f74c5b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T00:22:48.608162Z",
     "start_time": "2025-08-19T00:22:48.603519Z"
    }
   },
   "source": [
    "def scrape_html_docs(df, path):\n",
    "    \"\"\"Iterates over a DataFrame and saves HTML pages within multiple WebDriver sessions.\"\"\"\n",
    "    if not os.path.exists(path):\n",
    "        try:\n",
    "            os.makedirs(path)\n",
    "        except OSError as e:\n",
    "            logging.error(f\"Failed to create the {path} directory: {e}\")\n",
    "            sys.exit(1)\n",
    "\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df), desc='Scraping HTML documents'):\n",
    "        url = row['Post URL']\n",
    "        doc_id = row['Post ID']\n",
    "        filename = os.path.join(path, f\"{doc_id}.html\")\n",
    "\n",
    "        page_source = scrape_html(url)  # Call the scrape_html function\n",
    "\n",
    "        if page_source:\n",
    "            with open(filename, 'w', encoding='utf-8') as file:\n",
    "                file.write(page_source)\n",
    "            logging.info(f\"Saved: {filename}\")"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "id": "7ba455474af4bc4b",
   "metadata": {},
   "source": [
    "## Scraping [Greenpeace Stories](https://www.greenpeace.org/international/story/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a800858be531266",
   "metadata": {},
   "source": [
    "### Define local variables"
   ]
  },
  {
   "cell_type": "code",
   "id": "8b141ef27be1ff09",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T00:22:53.046815Z",
     "start_time": "2025-08-19T00:22:53.043611Z"
    }
   },
   "source": [
    "id = 'grp'\n",
    "path = os.path.join(output_directory, id)\n",
    "dataset_filename_1 = f\"{id}_list\"\n",
    "dataset_filename_2 = f\"{id}\""
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "b9f4345adc617bce",
   "metadata": {},
   "source": [
    "### Create output subdirectory"
   ]
  },
  {
   "cell_type": "code",
   "id": "5c77a6049e029a22",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T00:22:56.174395Z",
     "start_time": "2025-08-19T00:22:56.171031Z"
    }
   },
   "source": [
    "create_directory(path)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory already exists: cl_st2_ph1_arianne/grp\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "id": "12741feb2537795d",
   "metadata": {},
   "source": [
    "### Capture a few document pages for inspection"
   ]
  },
  {
   "cell_type": "code",
   "id": "b22eb22a0eed40cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-17T18:25:04.035742Z",
     "start_time": "2025-08-17T18:25:04.031963Z"
    }
   },
   "source": [
    "filename_sample_1 = 'greenpeace_stories_sample1.html'\n",
    "url_sample_1 = 'https://www.greenpeace.org/international/story/page/1/'\n",
    "filename_sample_11 = 'greenpeace_stories_sample11.html'\n",
    "url_sample_11 = 'https://www.greenpeace.org/international/story/77736/from-hiroshima-to-gaza-defending-peace/'\n",
    "filename_sample_2 = 'greenpeace_stories_sample2.html'\n",
    "url_sample_2 = 'https://www.greenpeace.org/international/story/page/2/'\n",
    "filename_sample_21 = 'greenpeace_stories_sample21.html'\n",
    "url_sample_21 = 'https://www.greenpeace.org/international/story/77406/boots-to-boost-justice-standing-in-solidarity-with-indonesian-migrant-fishers/'\n",
    "filename_sample_3 = 'greenpeace_stories_sample3.html'\n",
    "url_sample_3 = 'https://www.greenpeace.org/international/story/page/3/'\n",
    "filename_sample_31 = 'greenpeace_stories_sample31.html'\n",
    "url_sample_31 = 'https://www.greenpeace.org/international/story/76810/vanishing-millet-fields-endangered-sparrows-the-climate-crisis-and-taiwans-forgotten-guardians/'"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "5aa51a45833b3f03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-17T18:25:09.811132Z",
     "start_time": "2025-08-17T18:25:04.081812Z"
    }
   },
   "source": [
    "document_page_sample_1 = scrape_html(url_sample_1)\n",
    "\n",
    "with open(f'{path}/{filename_sample_1}', 'w', encoding='utf8', newline='\\n') as file:\n",
    "    file.write(document_page_sample_1)"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "7882b7a20395a30a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-17T18:25:16.873566Z",
     "start_time": "2025-08-17T18:25:09.939629Z"
    }
   },
   "source": [
    "document_page_sample_11 = scrape_html(url_sample_11)\n",
    "\n",
    "with open(f'{path}/{filename_sample_11}', 'w', encoding='utf8', newline='\\n') as file:\n",
    "    file.write(document_page_sample_11)"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "id": "31febd2f94481e3b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-17T18:25:24.777507Z",
     "start_time": "2025-08-17T18:25:16.897424Z"
    }
   },
   "source": [
    "document_page_sample_2 = scrape_html(url_sample_2)\n",
    "\n",
    "with open(f'{path}/{filename_sample_2}', 'w', encoding='utf8', newline='\\n') as file:\n",
    "    file.write(document_page_sample_2)"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "id": "1d56dd409f7a82de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-17T18:25:32.296811Z",
     "start_time": "2025-08-17T18:25:24.794426Z"
    }
   },
   "source": [
    "document_page_sample_21 = scrape_html(url_sample_21)\n",
    "\n",
    "with open(f'{path}/{filename_sample_21}', 'w', encoding='utf8', newline='\\n') as file:\n",
    "    file.write(document_page_sample_21)"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "id": "ffb47da31973ab27",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-17T18:25:40.826842Z",
     "start_time": "2025-08-17T18:25:32.315892Z"
    }
   },
   "source": [
    "document_page_sample_3 = scrape_html(url_sample_3)\n",
    "\n",
    "with open(f'{path}/{filename_sample_3}', 'w', encoding='utf8', newline='\\n') as file:\n",
    "    file.write(document_page_sample_3)"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "e4b384b766018ee9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-17T18:25:46.957816Z",
     "start_time": "2025-08-17T18:25:40.843961Z"
    }
   },
   "source": [
    "document_page_sample_31 = scrape_html(url_sample_31)\n",
    "\n",
    "with open(f'{path}/{filename_sample_31}', 'w', encoding='utf8', newline='\\n') as file:\n",
    "    file.write(document_page_sample_31)"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "id": "9cd43188047cde5e",
   "metadata": {},
   "source": [
    "### Scraping the post metadata"
   ]
  },
  {
   "cell_type": "code",
   "id": "7e4ed3a6e89f7821",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-17T18:25:46.985617Z",
     "start_time": "2025-08-17T18:25:46.976803Z"
    }
   },
   "source": [
    "def scrape_posts(source, index_page_url_1, index_page_url_2, start_page, end_page):\n",
    "    \"\"\"Iterates over a set of index pages and extracts post metadata.\"\"\"\n",
    "    data = []\n",
    "\n",
    "    for i in tqdm(range(start_page, end_page + 1)):\n",
    "        url = f\"{index_page_url_1}{i}{index_page_url_2}\"\n",
    "\n",
    "        index_page = scrape_html(url)\n",
    "\n",
    "        # Parse page source with BeautifulSoup\n",
    "        soup = BeautifulSoup(index_page, 'lxml')\n",
    "\n",
    "        # Capture the listing page content\n",
    "        listing_page_content = soup.find('div', id='listing-page-content')\n",
    "\n",
    "        # Extract the items\n",
    "        if listing_page_content:\n",
    "            list = listing_page_content.find('ul', class_='wp-block-post-template')\n",
    "            if list:\n",
    "                items = list.find_all('li')\n",
    "\n",
    "        for item in items:\n",
    "            # Extract the item body\n",
    "            body = item.find('div', class_='query-list-item-body')\n",
    "\n",
    "            # Extract the post term\n",
    "            if body:\n",
    "                post_term = body.find('div', class_='wp-block-post-terms')\n",
    "                if post_term:\n",
    "                    post_term_text = ' '.join(post_term.get_text(' ', strip=True).split()) if post_term else ''\n",
    "\n",
    "            # Extract the post tags\n",
    "            if body:\n",
    "                post_tags = body.find('div', class_='taxonomy-post_tag wp-block-post-terms')\n",
    "                if post_tags:\n",
    "                    post_tags_list = [a.get_text(strip=True) for a in post_tags.select('a[rel=\"tag\"]')]\n",
    "                    post_tags_text = \", \".join(post_tags_list) if post_tags_list else ''\n",
    "\n",
    "            # Extract the title\n",
    "            if body:\n",
    "                headline = body.find('h4', class_='query-list-item-headline wp-block-post-title')\n",
    "                title_text = ' '.join(headline.get_text(' ', strip=True).split()) if headline else ''\n",
    "\n",
    "            # Extract the post URL\n",
    "            if headline:\n",
    "                anchor_url = headline.find('a')\n",
    "                post_url = anchor_url['href'] if anchor_url else ''\n",
    "\n",
    "            ## Extract the category\n",
    "            #post_page = scrape_html(post_url)\n",
    "            #soup_article = BeautifulSoup(post_page, 'lxml')\n",
    "            #tag_wrap_issues = soup_article.find('div', class_='tag-wrap issues')\n",
    "            #if tag_wrap_issues:\n",
    "            #    anchor_category = tag_wrap_issues.find('a')\n",
    "            #    category_text = anchor_category.get_text(strip=True) if anchor_category else ''\n",
    "\n",
    "            # Extract the authors\n",
    "            if body:\n",
    "                authors = body.find('span', class_='article-list-item-author')\n",
    "                authors_text = ' '.join(authors.get_text(' ', strip=True).split()) if authors else ''\n",
    "\n",
    "            # Extract post date\n",
    "            if body:\n",
    "                post_date = body.find('div', class_='wp-block-post-date')\n",
    "                if post_date:\n",
    "                    time = post_date.find('time')\n",
    "                    post_date_time = time['datetime'] if time else ''\n",
    "\n",
    "            # Append the extracted data\n",
    "            data.append({\n",
    "                'Source': source,\n",
    "                'Post Term': post_term_text,\n",
    "                #'Category': category_text,\n",
    "                'Post Tags': post_tags_text,\n",
    "                'Title': title_text,\n",
    "                'Post URL': post_url,\n",
    "                'Authors': authors_text,\n",
    "                'Post Date': post_date_time\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(data)"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "id": "648647f99e93339a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T00:23:08.857466Z",
     "start_time": "2025-08-19T00:23:08.853858Z"
    }
   },
   "source": [
    "source = 'Greenpeace'\n",
    "index_page_url_1 = 'https://www.greenpeace.org/international/story/page/'\n",
    "index_page_url_2 = '/'\n",
    "start_page = 1\n",
    "end_page = 136"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "id": "8fb579a3ee89205a",
   "metadata": {},
   "source": "Note: On 17/08/2025, when the data was extracted, the end page was 136."
  },
  {
   "cell_type": "code",
   "id": "d093e6254ab6dbef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-17T18:25:54.291942Z",
     "start_time": "2025-08-17T18:25:47.006470Z"
    }
   },
   "source": [
    "df_grp = scrape_posts(source, index_page_url_1, index_page_url_2, start_page, end_page)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:07<00:00,  7.26s/it]\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "id": "88b4813261f7c6c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-17T18:25:54.348110Z",
     "start_time": "2025-08-17T18:25:54.331346Z"
    }
   },
   "source": [
    "df_grp['Post Date'] = pd.to_datetime(df_grp['Post Date'], errors='coerce', utc=True)"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "id": "23b6fceae805b031",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-17T18:25:54.365045Z",
     "start_time": "2025-08-17T18:25:54.358391Z"
    }
   },
   "source": [
    "df_grp['Post ID'] = id + df_grp.index.astype(str).str.zfill(6)"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "id": "8ae88142a9413b56",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T01:39:51.288327Z",
     "start_time": "2025-08-19T01:39:51.283046Z"
    }
   },
   "source": [
    "df_grp.dtypes"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Source               object\n",
       "Post Term            object\n",
       "Post Tags            object\n",
       "Title                object\n",
       "Post URL             object\n",
       "Authors              object\n",
       "Post Date    datetime64[ns]\n",
       "Post ID              object\n",
       "dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "id": "a6769754c76e665b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-17T18:25:54.522172Z",
     "start_time": "2025-08-17T18:25:54.504922Z"
    }
   },
   "source": [
    "df_grp"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       Source Post Term                          Post Tags  \\\n",
       "0  Greenpeace   Stories                        Photography   \n",
       "1  Greenpeace   Stories                            Forests   \n",
       "2  Greenpeace   Stories                 AlternativeFutures   \n",
       "3  Greenpeace   Stories                        Photography   \n",
       "4  Greenpeace   Stories                     Peace, Nuclear   \n",
       "5  Greenpeace   Stories                     Nuclear, Peace   \n",
       "6  Greenpeace   Stories                   Plastics, Oceans   \n",
       "7  Greenpeace   Stories                        Photography   \n",
       "8  Greenpeace   Stories  Climate, Health, PollutersPayPact   \n",
       "9  Greenpeace   Stories   EnergyRevolution, Peace, Nuclear   \n",
       "\n",
       "                                               Title  \\\n",
       "0                    Greenpeace Pictures of the Week   \n",
       "1  Environmental storytelling for a Chinese audie...   \n",
       "2  5 reasons Greenpeace calls for new global tax ...   \n",
       "3                    Greenpeace Pictures of the Week   \n",
       "4            From Hiroshima to Gaza: defending peace   \n",
       "5  80 years since Hiroshima and Nagasaki â€” time f...   \n",
       "6  More businesses join the call for a strong UN ...   \n",
       "7                    Greenpeace Pictures of the Week   \n",
       "8  The climate crisis hits health care in South A...   \n",
       "9  How can we protect peace and democracy? Greenp...   \n",
       "\n",
       "                                            Post URL  \\\n",
       "0  https://www.greenpeace.org/international/story...   \n",
       "1  https://www.greenpeace.org/international/story...   \n",
       "2  https://www.greenpeace.org/international/story...   \n",
       "3  https://www.greenpeace.org/international/story...   \n",
       "4  https://www.greenpeace.org/international/story...   \n",
       "5  https://www.greenpeace.org/international/story...   \n",
       "6  https://www.greenpeace.org/international/story...   \n",
       "7  https://www.greenpeace.org/international/story...   \n",
       "8  https://www.greenpeace.org/international/story...   \n",
       "9  https://www.greenpeace.org/international/story...   \n",
       "\n",
       "                    Authors                 Post Date    Post ID  \n",
       "0  Greenpeace International 2025-08-15 01:45:33+00:00  grp000000  \n",
       "1               August Rick 2025-08-14 01:40:25+00:00  grp000001  \n",
       "2                Nina Stros 2025-08-13 13:47:04+00:00  grp000002  \n",
       "3  Greenpeace International 2025-08-08 05:09:19+00:00  grp000003  \n",
       "4         Greenpeace France 2025-08-07 15:22:58+00:00  grp000004  \n",
       "5              Sam Annesley 2025-08-06 00:15:55+00:00  grp000005  \n",
       "6                Sarah King 2025-08-01 06:00:00+00:00  grp000006  \n",
       "7  Greenpeace International 2025-08-01 04:08:33+00:00  grp000007  \n",
       "8            Yoliswa Sobuwa 2025-07-31 09:05:58+00:00  grp000008  \n",
       "9            Camilo Sanchez 2025-07-30 11:58:55+00:00  grp000009  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Post Term</th>\n",
       "      <th>Post Tags</th>\n",
       "      <th>Title</th>\n",
       "      <th>Post URL</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Post Date</th>\n",
       "      <th>Post ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Stories</td>\n",
       "      <td>Photography</td>\n",
       "      <td>Greenpeace Pictures of the Week</td>\n",
       "      <td>https://www.greenpeace.org/international/story...</td>\n",
       "      <td>Greenpeace International</td>\n",
       "      <td>2025-08-15 01:45:33+00:00</td>\n",
       "      <td>grp000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Stories</td>\n",
       "      <td>Forests</td>\n",
       "      <td>Environmental storytelling for a Chinese audie...</td>\n",
       "      <td>https://www.greenpeace.org/international/story...</td>\n",
       "      <td>August Rick</td>\n",
       "      <td>2025-08-14 01:40:25+00:00</td>\n",
       "      <td>grp000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Stories</td>\n",
       "      <td>AlternativeFutures</td>\n",
       "      <td>5 reasons Greenpeace calls for new global tax ...</td>\n",
       "      <td>https://www.greenpeace.org/international/story...</td>\n",
       "      <td>Nina Stros</td>\n",
       "      <td>2025-08-13 13:47:04+00:00</td>\n",
       "      <td>grp000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Stories</td>\n",
       "      <td>Photography</td>\n",
       "      <td>Greenpeace Pictures of the Week</td>\n",
       "      <td>https://www.greenpeace.org/international/story...</td>\n",
       "      <td>Greenpeace International</td>\n",
       "      <td>2025-08-08 05:09:19+00:00</td>\n",
       "      <td>grp000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Stories</td>\n",
       "      <td>Peace, Nuclear</td>\n",
       "      <td>From Hiroshima to Gaza: defending peace</td>\n",
       "      <td>https://www.greenpeace.org/international/story...</td>\n",
       "      <td>Greenpeace France</td>\n",
       "      <td>2025-08-07 15:22:58+00:00</td>\n",
       "      <td>grp000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Stories</td>\n",
       "      <td>Nuclear, Peace</td>\n",
       "      <td>80 years since Hiroshima and Nagasaki â€” time f...</td>\n",
       "      <td>https://www.greenpeace.org/international/story...</td>\n",
       "      <td>Sam Annesley</td>\n",
       "      <td>2025-08-06 00:15:55+00:00</td>\n",
       "      <td>grp000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Stories</td>\n",
       "      <td>Plastics, Oceans</td>\n",
       "      <td>More businesses join the call for a strong UN ...</td>\n",
       "      <td>https://www.greenpeace.org/international/story...</td>\n",
       "      <td>Sarah King</td>\n",
       "      <td>2025-08-01 06:00:00+00:00</td>\n",
       "      <td>grp000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Stories</td>\n",
       "      <td>Photography</td>\n",
       "      <td>Greenpeace Pictures of the Week</td>\n",
       "      <td>https://www.greenpeace.org/international/story...</td>\n",
       "      <td>Greenpeace International</td>\n",
       "      <td>2025-08-01 04:08:33+00:00</td>\n",
       "      <td>grp000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Stories</td>\n",
       "      <td>Climate, Health, PollutersPayPact</td>\n",
       "      <td>The climate crisis hits health care in South A...</td>\n",
       "      <td>https://www.greenpeace.org/international/story...</td>\n",
       "      <td>Yoliswa Sobuwa</td>\n",
       "      <td>2025-07-31 09:05:58+00:00</td>\n",
       "      <td>grp000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Stories</td>\n",
       "      <td>EnergyRevolution, Peace, Nuclear</td>\n",
       "      <td>How can we protect peace and democracy? Greenp...</td>\n",
       "      <td>https://www.greenpeace.org/international/story...</td>\n",
       "      <td>Camilo Sanchez</td>\n",
       "      <td>2025-07-30 11:58:55+00:00</td>\n",
       "      <td>grp000009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "id": "a92fe2e83c49a37e",
   "metadata": {},
   "source": [
    "#### Export to a file"
   ]
  },
  {
   "cell_type": "code",
   "id": "5b313a713db23d83",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-17T18:25:54.888211Z",
     "start_time": "2025-08-17T18:25:54.858579Z"
    }
   },
   "source": [
    "df_grp.to_json(f\"{output_directory}/{dataset_filename_1}.jsonl\", orient='records', lines=True)"
   ],
   "outputs": [],
   "execution_count": 25
  },
  {
   "cell_type": "markdown",
   "id": "2d296641cca1b3e9",
   "metadata": {},
   "source": [
    "### Scrape the posts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472cfcf099f77932",
   "metadata": {},
   "source": [
    "#### Import the data into a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "id": "6f4a8a03e79cbd41",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T00:23:38.850115Z",
     "start_time": "2025-08-19T00:23:38.816330Z"
    }
   },
   "source": [
    "df_grp = pd.read_json(f\"{input_directory}/{dataset_filename_1}.jsonl\", lines=True)"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "5a9d2a7880cc6530",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T00:23:42.494245Z",
     "start_time": "2025-08-19T00:23:42.490247Z"
    }
   },
   "source": [
    "df_grp['Post Date'] = pd.to_datetime(df_grp['Post Date'], unit='ms')"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "id": "aa8e70c3af2b2549",
   "metadata": {},
   "source": [
    "#### Scrape the posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b82ad4481a82c218",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-15T22:10:17.794922Z",
     "start_time": "2025-08-15T22:09:06.470012Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping HTML documents: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:56<00:00,  5.66s/it]\n"
     ]
    }
   ],
   "source": [
    "scrape_html_docs(df_grp, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4eafbd66410fc22",
   "metadata": {},
   "source": [
    "### Extract the text from the posts"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T00:25:26.473115Z",
     "start_time": "2025-08-19T00:25:26.466127Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_text(df, path):\n",
    "    \"\"\"Extracts text from HTML files and saves as text files.\"\"\"\n",
    "\n",
    "    for post_id in df['Post ID']:\n",
    "        html_file = os.path.join(path, f\"{post_id}.html\")\n",
    "        txt_file = os.path.join(path, f\"{post_id}.txt\")\n",
    "\n",
    "        # Check if the HTML file exists\n",
    "        if not os.path.exists(html_file):\n",
    "            logging.error(f\"Skipping {html_file}: File not found\")\n",
    "            continue\n",
    "\n",
    "        # Read HTML content\n",
    "        with open(html_file, 'r', encoding='utf-8') as file:\n",
    "            soup = BeautifulSoup(file, 'lxml')\n",
    "\n",
    "        # Initialise text variable\n",
    "        text = ''\n",
    "\n",
    "        # Web Scraping - Begin\n",
    "\n",
    "        # Capture the 'article body'\n",
    "        post_body = soup.find('article')\n",
    "\n",
    "        # Extract the category\n",
    "        if post_body:\n",
    "            tag_wrap_issues = post_body.find('div', class_='tag-wrap issues')\n",
    "            if tag_wrap_issues:\n",
    "                anchor_category = tag_wrap_issues.find('a')\n",
    "                if anchor_category:\n",
    "                    category_text = ' '.join(anchor_category.get_text(' ', strip=True).split())\n",
    "                    text += f\"Category: {category_text}\\n\"\n",
    "\n",
    "        # Extract the paragraphs\n",
    "        if post_body:\n",
    "            post_content = post_body.find('div', class_='post-content')\n",
    "            if post_content:\n",
    "                post_details = post_content.find('div', class_='post-details clearfix')\n",
    "                if post_details:\n",
    "                    # Iterate top-level content blocks in order: paragraphs and lists\n",
    "                    for block in post_details.find_all(['p', 'ul', 'ol'], recursive=False):\n",
    "                        if block.name == 'p':\n",
    "                            paragraph_text = ' '.join(block.get_text(' ', strip=True).split())\n",
    "                            text += f\"{paragraph_text}\\n\"\n",
    "                        elif block.name in ('ul', 'ol'):\n",
    "                            # Capture top-level list items in order\n",
    "                            for li in block.find_all('li', recursive=False):\n",
    "                                li_text = ' '.join(li.get_text(' ', strip=True).split())\n",
    "                                text += f\"{li_text}\\n\"\n",
    "\n",
    "        # Web Scraping - End\n",
    "\n",
    "        # Save text to a text file\n",
    "        with open(txt_file, 'w', encoding='utf-8', newline='\\n') as file:\n",
    "            file.write(text)\n",
    "\n",
    "        logging.info(f\"Saved text for {post_id} to {txt_file}\")"
   ],
   "id": "8ec608d506db368b",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T01:38:00.629884Z",
     "start_time": "2025-08-19T01:37:05.750706Z"
    }
   },
   "cell_type": "code",
   "source": "extract_text(df_grp, path)",
   "id": "51525f10063d5779",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T00:25:26.473115Z",
     "start_time": "2025-08-19T00:25:26.466127Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 14,
   "source": [
    "def extract_text_gp000071_gp001092(df, path):\n",
    "    \"\"\"Extracts text from HTML files and saves as text files.\"\"\"\n",
    "\n",
    "    for post_id in df['Post ID']:\n",
    "        html_file = os.path.join(path, f\"{post_id}.html\")\n",
    "        txt_file = os.path.join(path, f\"{post_id}.txt\")\n",
    "\n",
    "        # Check if the HTML file exists\n",
    "        if not os.path.exists(html_file):\n",
    "            logging.error(f\"Skipping {html_file}: File not found\")\n",
    "            continue\n",
    "\n",
    "        # Read HTML content\n",
    "        with open(html_file, 'r', encoding='utf-8') as file:\n",
    "            soup = BeautifulSoup(file, 'lxml')\n",
    "\n",
    "        # Initialise text variable\n",
    "        text = ''\n",
    "\n",
    "        # Web Scraping - Begin\n",
    "\n",
    "        # Capture the 'article body'\n",
    "        post_body = soup.find('article')\n",
    "\n",
    "        # Extract the category\n",
    "        if post_body:\n",
    "            tag_wrap_issues = post_body.find('div', class_='tag-wrap issues')\n",
    "            if tag_wrap_issues:\n",
    "                anchor_category = tag_wrap_issues.find('a')\n",
    "                if anchor_category:\n",
    "                    category_text = ' '.join(anchor_category.get_text(' ', strip=True).split())\n",
    "                    text += f\"Category: {category_text}\\n\"\n",
    "\n",
    "        # Extract the paragraphs\n",
    "        if post_body:\n",
    "            post_content = post_body.find('div', class_='post-content')\n",
    "            if post_content:\n",
    "                post_details = post_content.find('div', class_='post-details clearfix')\n",
    "                if post_details:\n",
    "                    # Iterate top-level content blocks in order: paragraphs and lists\n",
    "                    for block in post_details.find_all(['p', 'ul', 'ol'], recursive=True):\n",
    "                        if block.name == 'p':\n",
    "                            paragraph_text = ' '.join(block.get_text(' ', strip=True).split())\n",
    "                            text += f\"{paragraph_text}\\n\"\n",
    "                        elif block.name in ('ul', 'ol'):\n",
    "                            # Capture top-level list items in order\n",
    "                            for li in block.find_all('li', recursive=False):\n",
    "                                li_text = ' '.join(li.get_text(' ', strip=True).split())\n",
    "                                text += f\"{li_text}\\n\"\n",
    "\n",
    "        # Web Scraping - End\n",
    "\n",
    "        # Save text to a text file\n",
    "        with open(txt_file, 'w', encoding='utf-8', newline='\\n') as file:\n",
    "            file.write(text)\n",
    "\n",
    "        logging.info(f\"Saved text for {post_id} to {txt_file}\")"
   ],
   "id": "b90b6fd6938af534"
  },
  {
   "cell_type": "markdown",
   "id": "1802069d1b6d7c3f",
   "metadata": {},
   "source": [
    "### Break down the texts into paragraphs"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T01:39:49.107381Z",
     "start_time": "2025-08-19T01:39:48.050540Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Prepare to collect rows\n",
    "data = []\n",
    "\n",
    "# Loop through each 'Post ID' in the DataFrame\n",
    "for _, row in df_grp.iterrows():\n",
    "    post_id = row['Post ID']\n",
    "\n",
    "    paragraph_count = 0\n",
    "    file_path = os.path.join(path, f\"{post_id}.txt\")\n",
    "\n",
    "    if not os.path.isfile(file_path):\n",
    "        print(f\"Missing file: {file_path}\")\n",
    "        continue\n",
    "\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            line = ' '.join(line.split()).strip()\n",
    "            if not line:\n",
    "                continue\n",
    "\n",
    "            if line.startswith('Category:'):\n",
    "                category_name = line.partition(':')[2].strip()\n",
    "                # If a category line is blank or only has the colon, we gracefully assign the fallback name 'Undefined Category'\n",
    "                category = category_name if category_name else 'Undefined Category'\n",
    "                paragraph_count = 0 # Resetting paragraph count for new category\n",
    "\n",
    "            elif line:\n",
    "                paragraph_count += 1\n",
    "                data.append({\n",
    "                    'Post ID': post_id,\n",
    "                    'Category': category,\n",
    "                    'Paragraph': f\"Paragraph {paragraph_count}\",\n",
    "                    'Text Paragraph': line\n",
    "                    })\n",
    "\n",
    "# Create final DataFrame\n",
    "df_paragraph = pd.DataFrame(data)"
   ],
   "id": "e8ce57fc839c0de2",
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T01:33:50.991621Z",
     "start_time": "2025-08-19T01:33:50.979170Z"
    }
   },
   "cell_type": "code",
   "source": "df_paragraph",
   "id": "5e138d14129fb9d4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         Post ID    Category     Paragraph  \\\n",
       "0      grp000000  Greenpeace   Paragraph 1   \n",
       "1      grp000000  Greenpeace   Paragraph 2   \n",
       "2      grp000000  Greenpeace   Paragraph 3   \n",
       "3      grp000000  Greenpeace   Paragraph 4   \n",
       "4      grp000000  Greenpeace   Paragraph 5   \n",
       "...          ...         ...           ...   \n",
       "23363  grp001356  Greenpeace  Paragraph 13   \n",
       "23364  grp001356  Greenpeace  Paragraph 14   \n",
       "23365  grp001356  Greenpeace  Paragraph 15   \n",
       "23366  grp001356  Greenpeace  Paragraph 16   \n",
       "23367  grp001356  Greenpeace  Paragraph 17   \n",
       "\n",
       "                                          Text Paragraph  \n",
       "0      From a banner protest at the plastic treaty in...  \n",
       "1      ðŸ‡¬ðŸ‡§ England â€“ Greenpeace UKâ€™s climbers install ...  \n",
       "2      After securing a giant 12m x 8m canvas to one ...  \n",
       "3      The work starkly visualises the wound inflicte...  \n",
       "4      ðŸ‡¨ðŸ‡­ Switzerland â€“ Juan Carlos Monterrey GÃ³mez, ...  \n",
       "...                                                  ...  \n",
       "23363  He joined Torontoâ€™s City TV as an ecology spec...  \n",
       "23364  Over the years he continued to contribute to G...  \n",
       "23365  In a recent book, Rex Weyler writes about refl...  \n",
       "23366  â€œThe ironies and tension of history simultaneo...  \n",
       "23367  Bob Hunter made much of his opportunity to ser...  \n",
       "\n",
       "[23368 rows x 4 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Post ID</th>\n",
       "      <th>Category</th>\n",
       "      <th>Paragraph</th>\n",
       "      <th>Text Paragraph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>grp000000</td>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Paragraph 1</td>\n",
       "      <td>From a banner protest at the plastic treaty in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>grp000000</td>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Paragraph 2</td>\n",
       "      <td>ðŸ‡¬ðŸ‡§ England â€“ Greenpeace UKâ€™s climbers install ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>grp000000</td>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Paragraph 3</td>\n",
       "      <td>After securing a giant 12m x 8m canvas to one ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>grp000000</td>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Paragraph 4</td>\n",
       "      <td>The work starkly visualises the wound inflicte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>grp000000</td>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Paragraph 5</td>\n",
       "      <td>ðŸ‡¨ðŸ‡­ Switzerland â€“ Juan Carlos Monterrey GÃ³mez, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23363</th>\n",
       "      <td>grp001356</td>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Paragraph 13</td>\n",
       "      <td>He joined Torontoâ€™s City TV as an ecology spec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23364</th>\n",
       "      <td>grp001356</td>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Paragraph 14</td>\n",
       "      <td>Over the years he continued to contribute to G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23365</th>\n",
       "      <td>grp001356</td>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Paragraph 15</td>\n",
       "      <td>In a recent book, Rex Weyler writes about refl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23366</th>\n",
       "      <td>grp001356</td>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Paragraph 16</td>\n",
       "      <td>â€œThe ironies and tension of history simultaneo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23367</th>\n",
       "      <td>grp001356</td>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Paragraph 17</td>\n",
       "      <td>Bob Hunter made much of his opportunity to ser...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23368 rows Ã— 4 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "id": "e2e1d9af365ed797",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T01:39:57.954449Z",
     "start_time": "2025-08-19T01:39:57.931085Z"
    }
   },
   "source": [
    "df_grp_paragraph = df_grp.merge(df_paragraph, on='Post ID', how='left')"
   ],
   "outputs": [],
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "id": "638f21b10c8540cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T01:40:01.818078Z",
     "start_time": "2025-08-19T01:40:01.800762Z"
    }
   },
   "source": [
    "df_grp_paragraph"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "           Source Post Term         Post Tags  \\\n",
       "0      Greenpeace   Stories       Photography   \n",
       "1      Greenpeace   Stories       Photography   \n",
       "2      Greenpeace   Stories       Photography   \n",
       "3      Greenpeace   Stories       Photography   \n",
       "4      Greenpeace   Stories       Photography   \n",
       "...           ...       ...               ...   \n",
       "23365  Greenpeace   Stories  AboutUs, 50Years   \n",
       "23366  Greenpeace   Stories  AboutUs, 50Years   \n",
       "23367  Greenpeace   Stories  AboutUs, 50Years   \n",
       "23368  Greenpeace   Stories  AboutUs, 50Years   \n",
       "23369  Greenpeace   Stories  AboutUs, 50Years   \n",
       "\n",
       "                                 Title  \\\n",
       "0      Greenpeace Pictures of the Week   \n",
       "1      Greenpeace Pictures of the Week   \n",
       "2      Greenpeace Pictures of the Week   \n",
       "3      Greenpeace Pictures of the Week   \n",
       "4      Greenpeace Pictures of the Week   \n",
       "...                                ...   \n",
       "23365           Bob Hunter 1941 â€“ 2005   \n",
       "23366           Bob Hunter 1941 â€“ 2005   \n",
       "23367           Bob Hunter 1941 â€“ 2005   \n",
       "23368           Bob Hunter 1941 â€“ 2005   \n",
       "23369           Bob Hunter 1941 â€“ 2005   \n",
       "\n",
       "                                                Post URL  \\\n",
       "0      https://www.greenpeace.org/international/story...   \n",
       "1      https://www.greenpeace.org/international/story...   \n",
       "2      https://www.greenpeace.org/international/story...   \n",
       "3      https://www.greenpeace.org/international/story...   \n",
       "4      https://www.greenpeace.org/international/story...   \n",
       "...                                                  ...   \n",
       "23365  https://www.greenpeace.org/international/story...   \n",
       "23366  https://www.greenpeace.org/international/story...   \n",
       "23367  https://www.greenpeace.org/international/story...   \n",
       "23368  https://www.greenpeace.org/international/story...   \n",
       "23369  https://www.greenpeace.org/international/story...   \n",
       "\n",
       "                        Authors           Post Date    Post ID    Category  \\\n",
       "0      Greenpeace International 2025-08-15 01:45:33  grp000000  Greenpeace   \n",
       "1      Greenpeace International 2025-08-15 01:45:33  grp000000  Greenpeace   \n",
       "2      Greenpeace International 2025-08-15 01:45:33  grp000000  Greenpeace   \n",
       "3      Greenpeace International 2025-08-15 01:45:33  grp000000  Greenpeace   \n",
       "4      Greenpeace International 2025-08-15 01:45:33  grp000000  Greenpeace   \n",
       "...                         ...                 ...        ...         ...   \n",
       "23365  Greenpeace International 2005-05-02 15:15:00  grp001356  Greenpeace   \n",
       "23366  Greenpeace International 2005-05-02 15:15:00  grp001356  Greenpeace   \n",
       "23367  Greenpeace International 2005-05-02 15:15:00  grp001356  Greenpeace   \n",
       "23368  Greenpeace International 2005-05-02 15:15:00  grp001356  Greenpeace   \n",
       "23369  Greenpeace International 2005-05-02 15:15:00  grp001356  Greenpeace   \n",
       "\n",
       "          Paragraph                                     Text Paragraph  \n",
       "0       Paragraph 1  From a banner protest at the plastic treaty in...  \n",
       "1       Paragraph 2  ðŸ‡¬ðŸ‡§ England â€“ Greenpeace UKâ€™s climbers install ...  \n",
       "2       Paragraph 3  After securing a giant 12m x 8m canvas to one ...  \n",
       "3       Paragraph 4  The work starkly visualises the wound inflicte...  \n",
       "4       Paragraph 5  ðŸ‡¨ðŸ‡­ Switzerland â€“ Juan Carlos Monterrey GÃ³mez, ...  \n",
       "...             ...                                                ...  \n",
       "23365  Paragraph 13  He joined Torontoâ€™s City TV as an ecology spec...  \n",
       "23366  Paragraph 14  Over the years he continued to contribute to G...  \n",
       "23367  Paragraph 15  In a recent book, Rex Weyler writes about refl...  \n",
       "23368  Paragraph 16  â€œThe ironies and tension of history simultaneo...  \n",
       "23369  Paragraph 17  Bob Hunter made much of his opportunity to ser...  \n",
       "\n",
       "[23370 rows x 11 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Post Term</th>\n",
       "      <th>Post Tags</th>\n",
       "      <th>Title</th>\n",
       "      <th>Post URL</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Post Date</th>\n",
       "      <th>Post ID</th>\n",
       "      <th>Category</th>\n",
       "      <th>Paragraph</th>\n",
       "      <th>Text Paragraph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Stories</td>\n",
       "      <td>Photography</td>\n",
       "      <td>Greenpeace Pictures of the Week</td>\n",
       "      <td>https://www.greenpeace.org/international/story...</td>\n",
       "      <td>Greenpeace International</td>\n",
       "      <td>2025-08-15 01:45:33</td>\n",
       "      <td>grp000000</td>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Paragraph 1</td>\n",
       "      <td>From a banner protest at the plastic treaty in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Stories</td>\n",
       "      <td>Photography</td>\n",
       "      <td>Greenpeace Pictures of the Week</td>\n",
       "      <td>https://www.greenpeace.org/international/story...</td>\n",
       "      <td>Greenpeace International</td>\n",
       "      <td>2025-08-15 01:45:33</td>\n",
       "      <td>grp000000</td>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Paragraph 2</td>\n",
       "      <td>ðŸ‡¬ðŸ‡§ England â€“ Greenpeace UKâ€™s climbers install ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Stories</td>\n",
       "      <td>Photography</td>\n",
       "      <td>Greenpeace Pictures of the Week</td>\n",
       "      <td>https://www.greenpeace.org/international/story...</td>\n",
       "      <td>Greenpeace International</td>\n",
       "      <td>2025-08-15 01:45:33</td>\n",
       "      <td>grp000000</td>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Paragraph 3</td>\n",
       "      <td>After securing a giant 12m x 8m canvas to one ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Stories</td>\n",
       "      <td>Photography</td>\n",
       "      <td>Greenpeace Pictures of the Week</td>\n",
       "      <td>https://www.greenpeace.org/international/story...</td>\n",
       "      <td>Greenpeace International</td>\n",
       "      <td>2025-08-15 01:45:33</td>\n",
       "      <td>grp000000</td>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Paragraph 4</td>\n",
       "      <td>The work starkly visualises the wound inflicte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Stories</td>\n",
       "      <td>Photography</td>\n",
       "      <td>Greenpeace Pictures of the Week</td>\n",
       "      <td>https://www.greenpeace.org/international/story...</td>\n",
       "      <td>Greenpeace International</td>\n",
       "      <td>2025-08-15 01:45:33</td>\n",
       "      <td>grp000000</td>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Paragraph 5</td>\n",
       "      <td>ðŸ‡¨ðŸ‡­ Switzerland â€“ Juan Carlos Monterrey GÃ³mez, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23365</th>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Stories</td>\n",
       "      <td>AboutUs, 50Years</td>\n",
       "      <td>Bob Hunter 1941 â€“ 2005</td>\n",
       "      <td>https://www.greenpeace.org/international/story...</td>\n",
       "      <td>Greenpeace International</td>\n",
       "      <td>2005-05-02 15:15:00</td>\n",
       "      <td>grp001356</td>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Paragraph 13</td>\n",
       "      <td>He joined Torontoâ€™s City TV as an ecology spec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23366</th>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Stories</td>\n",
       "      <td>AboutUs, 50Years</td>\n",
       "      <td>Bob Hunter 1941 â€“ 2005</td>\n",
       "      <td>https://www.greenpeace.org/international/story...</td>\n",
       "      <td>Greenpeace International</td>\n",
       "      <td>2005-05-02 15:15:00</td>\n",
       "      <td>grp001356</td>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Paragraph 14</td>\n",
       "      <td>Over the years he continued to contribute to G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23367</th>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Stories</td>\n",
       "      <td>AboutUs, 50Years</td>\n",
       "      <td>Bob Hunter 1941 â€“ 2005</td>\n",
       "      <td>https://www.greenpeace.org/international/story...</td>\n",
       "      <td>Greenpeace International</td>\n",
       "      <td>2005-05-02 15:15:00</td>\n",
       "      <td>grp001356</td>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Paragraph 15</td>\n",
       "      <td>In a recent book, Rex Weyler writes about refl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23368</th>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Stories</td>\n",
       "      <td>AboutUs, 50Years</td>\n",
       "      <td>Bob Hunter 1941 â€“ 2005</td>\n",
       "      <td>https://www.greenpeace.org/international/story...</td>\n",
       "      <td>Greenpeace International</td>\n",
       "      <td>2005-05-02 15:15:00</td>\n",
       "      <td>grp001356</td>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Paragraph 16</td>\n",
       "      <td>â€œThe ironies and tension of history simultaneo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23369</th>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Stories</td>\n",
       "      <td>AboutUs, 50Years</td>\n",
       "      <td>Bob Hunter 1941 â€“ 2005</td>\n",
       "      <td>https://www.greenpeace.org/international/story...</td>\n",
       "      <td>Greenpeace International</td>\n",
       "      <td>2005-05-02 15:15:00</td>\n",
       "      <td>grp001356</td>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Paragraph 17</td>\n",
       "      <td>Bob Hunter made much of his opportunity to ser...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23370 rows Ã— 11 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Find texts that are empty",
   "id": "868c915ab24f962e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T01:40:12.176430Z",
     "start_time": "2025-08-19T01:40:12.170588Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Find rows where the specified column has empty strings\n",
    "mask = df_grp_paragraph['Category'].isnull()\n",
    "\n",
    "# Get the corresponding 'Post ID' values\n",
    "post_ids_with_missing_text = df_grp_paragraph[mask]['Post ID'].tolist()\n",
    "\n",
    "post_ids_with_missing_text"
   ],
   "id": "bcd6d57fb89be712",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['grp000071', 'grp001092']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T01:40:23.946742Z",
     "start_time": "2025-08-19T01:40:23.933721Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_grp_empty = df_grp_paragraph[df_grp_paragraph['Category'].isnull()]\n",
    "df_grp_empty"
   ],
   "id": "c9d757f2e97f4610",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "           Source Post Term    Post Tags  \\\n",
       "1101   Greenpeace   Stories  Photography   \n",
       "18996  Greenpeace   Stories      Forests   \n",
       "\n",
       "                                                   Title  \\\n",
       "1101                   Behind the Lens: Marizilda Cruppe   \n",
       "18996  This company promised to stop deforestation. B...   \n",
       "\n",
       "                                                Post URL  \\\n",
       "1101   https://www.greenpeace.org/international/story...   \n",
       "18996  https://www.greenpeace.org/international/story...   \n",
       "\n",
       "                        Authors           Post Date    Post ID Category  \\\n",
       "1101   Greenpeace International 2025-04-06 06:00:00  grp000071      NaN   \n",
       "18996             Grant Rosoman 2018-05-21 04:34:08  grp001092      NaN   \n",
       "\n",
       "      Paragraph Text Paragraph  \n",
       "1101        NaN            NaN  \n",
       "18996       NaN            NaN  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Post Term</th>\n",
       "      <th>Post Tags</th>\n",
       "      <th>Title</th>\n",
       "      <th>Post URL</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Post Date</th>\n",
       "      <th>Post ID</th>\n",
       "      <th>Category</th>\n",
       "      <th>Paragraph</th>\n",
       "      <th>Text Paragraph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1101</th>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Stories</td>\n",
       "      <td>Photography</td>\n",
       "      <td>Behind the Lens: Marizilda Cruppe</td>\n",
       "      <td>https://www.greenpeace.org/international/story...</td>\n",
       "      <td>Greenpeace International</td>\n",
       "      <td>2025-04-06 06:00:00</td>\n",
       "      <td>grp000071</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18996</th>\n",
       "      <td>Greenpeace</td>\n",
       "      <td>Stories</td>\n",
       "      <td>Forests</td>\n",
       "      <td>This company promised to stop deforestation. B...</td>\n",
       "      <td>https://www.greenpeace.org/international/story...</td>\n",
       "      <td>Grant Rosoman</td>\n",
       "      <td>2018-05-21 04:34:08</td>\n",
       "      <td>grp001092</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Rescrape",
   "id": "916887215abfec20"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T01:35:38.108711Z",
     "start_time": "2025-08-19T01:35:24.630809Z"
    }
   },
   "cell_type": "code",
   "source": "scrape_html_docs(df_grp_empty, path)",
   "id": "f6833d2f23c54286",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping HTML documents: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:13<00:00,  6.73s/it]\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "extract_text_gp000071_gp001092(df_grp_empty, path)",
   "id": "bb90581bfd943d0f"
  },
  {
   "cell_type": "markdown",
   "id": "96e31052da81b7a5",
   "metadata": {},
   "source": [
    "#### Export to a file"
   ]
  },
  {
   "cell_type": "code",
   "id": "78f33d144be98470",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T01:54:08.239313Z",
     "start_time": "2025-08-19T01:54:07.943481Z"
    }
   },
   "source": [
    "df_grp_paragraph.to_json(f\"{output_directory}/{dataset_filename_2}.jsonl\", orient='records', lines=True)"
   ],
   "outputs": [],
   "execution_count": 48
  },
  {
   "cell_type": "code",
   "id": "ef3e74f35933826d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T01:54:18.959273Z",
     "start_time": "2025-08-19T01:54:10.907105Z"
    }
   },
   "source": [
    "df_grp_paragraph.to_excel(f\"{output_directory}/{dataset_filename_2}.xlsx\", index=False)"
   ],
   "outputs": [],
   "execution_count": 49
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
